[
  {
    "objectID": "posts/quarto-blog/quarto-blog.html",
    "href": "posts/quarto-blog/quarto-blog.html",
    "title": "R Quarto로 만드는 블로그",
    "section": "",
    "text": "Artwork by Allison Horst"
  },
  {
    "objectID": "posts/quarto-blog/quarto-blog.html#배경",
    "href": "posts/quarto-blog/quarto-blog.html#배경",
    "title": "R Quarto로 만드는 블로그",
    "section": "배경",
    "text": "배경\n제가 논문을 blogdown을 포함하는 bookdown으로 쓰게 된 건, R을 기반으로 한 데이터 분석 결과를 매번 업데이트 하는 과정에서 자잘한 변경을 모두 트래킹 하기 어려웠기 때문입니다. 재현 가능한 연구(reproducible research) 를 위해서라도 R로 논문을 쓰는 게 필요했고, 당시 블로그를 시작할까 도전하면서 며칠을 낑낑 댔던 기억이 나네요.\n이후 등장한 distill은 블로그에 최적화된 간결한 기능을 사용자 친화적인 함수로 제공하여 훨씬 간편해졌어요. distill은 인용, 각주 등이 잘 구현되어 있다는 점, 그리고 css를 잘 몰라도 기본적인 구성은 아주 쉽게 구현할 수 있다는 강점을 갖고 있습니다.\nDistill의 기능을 대부분 포괄하면서 가장 최근에 나온 Quarto Blog 툴은 자바스크립트(JS) 기반 부트스트랩5을 탑재하고 있어 개인화 작업이 손 쉬워 졌습니다."
  },
  {
    "objectID": "posts/quarto-blog/quarto-blog.html#r로-블로그-만드는-3가지-방법",
    "href": "posts/quarto-blog/quarto-blog.html#r로-블로그-만드는-3가지-방법",
    "title": "R Quarto로 만드는 블로그",
    "section": "R로 블로그 만드는 3가지 방법",
    "text": "R로 블로그 만드는 3가지 방법\n\nblogdown (2017 ~ ): R로 작성하는 html 기초 문법 제공\n\nbookdown 패키지의 서브 버전으로 기본 문법을 이해하면 다른 패키지나 시스템 이해도가 크게 높아집니다.\n\n온라인 ebook은 무료로 제공 되고 있습니다.\n\n패키지 저자 Yihui Xie의 공식 가이드북을 추천합니다.\n\ndistill (2018 ~ ): 블로그에 최적화된 레이아웃 제공\n\n과학 블로그, 기술 블로그에 최적화된 웹출판 도구로 패발된 패키지 입니다.\n\n수학식, 인용, 각주 등을 손쉽게 사용할 수 있도록 편의성을 제공합니다.\n\n각종 편의 기능을 제공하는 함수로 블로그 포스팅을 쉽고 빠르게 할 수 있어요.\n\nquarto 블로그 시스템에 distill을 차용하고 있기 때문에 레퍼런스로 활용할 만 합니다.\n\n공식 홈페이지는 여기 참고하세요.\n\nquarto (2022 ~ ): 패키지가 아닌 문서 작성 도구 distill 기능을 대부분 계승합니다.\n\nQuarto는 Posit에서 공식 개발, 확장 중인 시스템으로 빠르게 기능이 확장 되고 있습니다.\nR 생태계를 파이썬과 연결하려는 시스템 입니다.\nRStudio 외에 쥬피터노트북, VS Code에서도 사용할 수 있어요."
  },
  {
    "objectID": "posts/quarto-blog/quarto-blog.html#quarto-장점",
    "href": "posts/quarto-blog/quarto-blog.html#quarto-장점",
    "title": "R Quarto로 만드는 블로그",
    "section": "Quarto 장점",
    "text": "Quarto 장점\n\nR 패키지가 아닌 문서 작성 시스템 입니다.\n\nR 이외 파이썬 언어로도 작성 가능합니다.\n\n블로그, 홈페이지, MS워드, PDF, ePub 등 다양한 문서 작성을 지원합니다.\nQuarto -&gt; Github -&gt; 제3자 퍼블리싱 연계가 쉽습니다."
  },
  {
    "objectID": "posts/quarto-blog/quarto-blog.html#quarto-단점",
    "href": "posts/quarto-blog/quarto-blog.html#quarto-단점",
    "title": "R Quarto로 만드는 블로그",
    "section": "Quarto 단점",
    "text": "Quarto 단점\n\n개인화 하려면 배워야 할 게 많습니다.\n\nR마크다운, yaml, html, css, JS는 기본적으로 이해할 필요가 있어요.\ngit에 대한 기본 이해도 필요해요.\nNetlify 같은 호스팅 서비스도 필요해요.\n\n패키지가 아니라서 클릭 한 번으로 블로그 포스팅 템플릿이 자동 생성되지 않습니다.\n\n블로그 포스팅 마다 폴더를 만들고, 그 안에 Rmd(R마크다운) 파일을 개별 생성해야 합니다."
  },
  {
    "objectID": "posts/quarto-blog/quarto-blog.html#어떻게-시작하나요",
    "href": "posts/quarto-blog/quarto-blog.html#어떻게-시작하나요",
    "title": "R Quarto로 만드는 블로그",
    "section": "어떻게 시작하나요?",
    "text": "어떻게 시작하나요?\n\nQuarto 설치\nPosit 홈페이지에서 사용하는 OS 시스템에 맞는 버전을 다운로드 후 설치 합니다. 2024-02-15 1.4.550 버전이 출시 되었습니다.\n\n\nQuarto Blog 프로젝트 만들기\n가장 쉬운 방법은 RStudio에서 신규 프로젝트를 생성할 때, Quarto Blog를 선택하는 겁니다. 프로젝트에서 자동으로 기본 뼈대 구성에 필요한 폴더들과 파일을 만들어 줍니다. 일단은 개인화는 나중에 생각하고, 해당 템플릿을 활용해서 index.Rmd를 나의 블로그 포스팅으로 수정하기만 해도 블로그를 시작하는 거죠.\n여기까지 얼마나 걸릴까요? 블로그 포스팅 소재만 준비되어 있다면 하루도 안 걸립니다.\n\n\nGithub 연동하기\ngit에 대해 잘 모르거나 github를 써 보지 않았다면 처음에 조금 헤맬 수 있어요. 관련된 포스팅은 다음 기회에 자세히 하기로 하구요, 초보를 위한 usethis 패키지를 활용할께요.\n\n(1) 깃헙 계정 만들기\nGitHub 계정이 없다면 이번 기회에 만듭니다.\n\n\n(2) usethis 패키지 설치\nusethis 패키지를 설치 하고 불러 옵니다.\n\n#install.packages(\"usethis\")\nlibrary(usethis) \n\n\n\n(3) 깃헙 계정과 RStudio 연결\nHappy Git and GibHub for the useR을 참조하시면 왠만한 건 다 해결 될 거에요.\n우리가 참고할 부분은 17 Existing project, Github last입니다.\n\nusethis::use_git()\n\n\n\n(4) 깃 패널 확인\n위 명령을 실행하면 RStudio 우측 상단 Environment가 있는 패널에 ’Git’이라는 패널이 새로 생길 거에요.\n\n\n\nGit 패널이 생기면 성공\n\n\n\n\n(5) 깃헙 연결하는 개인화토큰(PAT) 만들기\n다음 명령을 실행하면 깃헙 내 계정으로 로그인하는 창이 브라우저에 뜹니다. 브라우저에서 로그인 하면 PAT 만드는 페이지로 바로 접속 됩니다.\n\ncreate_github_token()\n\nNote 빈 칸에 적당한 이름을 만들어서 저장합니다. 다음 페이지에서 창을 절대 닫지 마시고 생성된 PAT를 복사하세요.\n\n\n\nPAT만드는 깃헙페이지로 연결됩니다\n\n\n다음 코드를 실행해서 시스템에 생성한 PAT를 저장합니다. 저는 이미 PAT가 저장되어 있기 때문에, 다음과 같이 기존 코드를 바꾸냐는 옵션이 있는 점 참고해 주세요.\n\ngitcreds::gitcreds_set()\n\n\n\n\n콘솔에서 옵션을 선택해서 저장\n\n\n\n\n(6) 깃헙에 블로그 레포지토리 생성\n다음 코드를 실행해서 깃헙에 프로젝트 이름으로 새로운 레포지토리를 생성합니다.\n\nuse_github() \n\n깃헙 홈페이지에서 새로 만들어진 레포지토리를 확인 합니다. 아직은 비어 있을 거에요.\n\n\n(7) 첫 커밋을 실행\n(4)번에서 본 Git 패널로 다시 갑니다. 아직 git에 연동되지 않은 파일 리스트가 있을 겁니다. 다음과 같이 실행하세요.\n\nDiff 아이콘을 열고, 모두 선택해서(staged)\n\n커밋 메세지를 적어요\n\n나중에 변경 이력 관리하기 위해서 어떤 내용 변경인지 요약한다고 생각하면 됩니다.\n\n\ncommit 버튼 클릭\n\npush 버튼 클릭\n\n간혹 push 버튼이 활성화 되지 않을 경우가 있어요. 그럴 때는 Terminal로 이동해서 직접 git 연동을 시켜 줍니다.\n\ngit push origin main\n\n\n\n(8) 깃헙 홈페이지 확인\n제대로 업로드가 되었는지 깃헙 홈페이지에 레포지토리를 확인하세요."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n비개발자도 쉽게 카페24 API 인증 토큰 발급 받는 방법\n\n\n\n\n\n\ncafe24\n\n\napi\n\n\npython\n\n\ntokens\n\n\n\n\n\n\n2024-09-19\n\n\n박세희\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\n클라우드 데이터 웨어하우스 어떤 기준으로 고를까?\n\n\n\n\n\n\nbigquery\n\n\nsql\n\n\ndata warehouse\n\n\n\n\n\n\n2024-03-23\n\n\n박세희\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio에서 Copilot 쓰기\n\n\n\n\n\n\nbigquery\n\n\nRstudio\n\n\ncopilot\n\n\ngithub\n\n\n\n\n\n\n2024-03-21\n\n\n박세희\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto 블로그 SEO 최적화 3가지 꿀팁\n\n\n\n\n\n\nfeatured\n\n\nquarto\n\n\nR\n\n\nseo\n\n\n\n\n\n\n2024-03-14\n\n\n박세희\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\ndbplyr로 bigquery 데이터 추출하기\n\n\n\n\n\n\nfeatured\n\n\nbigquery\n\n\nR\n\n\ndbplyr\n\n\nsql\n\n\n\n\n\n\n2024-03-14\n\n\n박세희\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nR에서 구글빅쿼리 데이터 추출하기\n\n\n\n\n\n\nfeatured\n\n\nbigquery\n\n\nsql\n\n\nR\n\n\n\n\n\n\n2024-02-26\n\n\n박세희\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nR Quarto로 만든 블로그 배포(feat. Netlify)\n\n\n\n\n\n\nfeatured\n\n\ngit\n\n\nquarto\n\n\nnetlify\n\n\n\n\n\n\n2024-02-24\n\n\n박세희\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nR Quarto로 만드는 블로그\n\n\n\n\n\n\nfeatured\n\n\ngit\n\n\nquarto\n\n\nR\n\n\n\n\n\n\n2024-02-23\n\n\n박세희\n\n\n5 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Mindful Analytics",
    "section": "",
    "text": "R | Python | Docker | JS\n네트워크 분석 | 예측 모델링 | 자연어처리(NLP)\n수석데이터분석가/CTO @ 딜리버디 (2022. 9 ~ 현재)\n겸임교수 @ 한국뉴욕주립대 SBU 기술경영학과 (2023. 1 ~ 현재)\n책임연구원/팀장 @ 한국산업기술진흥원 (2006.2 ~ 2022. 9)\n지혜로움 | 미션지향 | 효율추구 | 맛집탐방"
  },
  {
    "objectID": "about.html#박세희bak-seh-hui-ph.d.",
    "href": "about.html#박세희bak-seh-hui-ph.d.",
    "title": "Mindful Analytics",
    "section": "",
    "text": "R | Python | Docker | JS\n네트워크 분석 | 예측 모델링 | 자연어처리(NLP)\n수석데이터분석가/CTO @ 딜리버디 (2022. 9 ~ 현재)\n겸임교수 @ 한국뉴욕주립대 SBU 기술경영학과 (2023. 1 ~ 현재)\n책임연구원/팀장 @ 한국산업기술진흥원 (2006.2 ~ 2022. 9)\n지혜로움 | 미션지향 | 효율추구 | 맛집탐방"
  },
  {
    "objectID": "posts/quarto-blog/quarto-blog.html#사용-소감",
    "href": "posts/quarto-blog/quarto-blog.html#사용-소감",
    "title": "R Quarto로 만드는 블로그",
    "section": "사용 소감",
    "text": "사용 소감\n글이 너무 길어져서… 웹에 배포하는 Netlify 연동은 다음 포스팅에서 다룰께요.\nNetlify 연동방법 글 바로가기\nQuarto 설치 후 첫 블로그 포스팅 까지 딱 하루가 걸렸어요. 물론 저는 R 사용에 능숙하고 기존에 blogdown, distill 썼던 경험이 있어서 수월 했을 수도 있다고 생각합니다. 그럼에도 Quarto가 워낙 사용하기 쉽기 때문에 개발자가 아니어도 누구나 R을 활용한 블로그를 개설할 수 있습니다. Wordpress 블로그 개설이 너무 어려웠다면, Quarto를 찬찬히 따라해 보는 것 추천합니다. 여러분도 할 수 있어요.\n\n\n\nArtwork by Allison Horst\nGit 패널이 생기면 성공\nPAT만드는 깃헙페이지로 연결됩니다\n콘솔에서 옵션을 선택해서 저장"
  },
  {
    "objectID": "posts/netlify-deployment/netlify-deployment.html",
    "href": "posts/netlify-deployment/netlify-deployment.html",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "",
    "text": "Artwork by Allison Horst"
  },
  {
    "objectID": "posts/netlify-deployment/netlify-deployment.html#먼저-참고하면-좋은-글",
    "href": "posts/netlify-deployment/netlify-deployment.html#먼저-참고하면-좋은-글",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "먼저 참고하면 좋은 글",
    "text": "먼저 참고하면 좋은 글\nR Quarto로 블로그 만들기\n\nQuarto로 하루 만에 블로그 만드는 방법이 궁금하다면?\nGitHub와 Quarto 블로그 프로젝트를 연결하려면?"
  },
  {
    "objectID": "posts/netlify-deployment/netlify-deployment.html#netlify가-무엇이죠",
    "href": "posts/netlify-deployment/netlify-deployment.html#netlify가-무엇이죠",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "Netlify가 무엇이죠?",
    "text": "Netlify가 무엇이죠?\n정적 웹사이트를 호스팅하고 관리할 수 있는 무료 플랫폼 입니다. R 커뮤니티 뿐만 아니라 기술 블로그를 운영하는 다양한 개발자 커뮤니티에서 인기있는 서비스 입니다.1 Quarto 블로그는 기본적으로 미리 knit을 통해 완성한 html을 서버로 전송하는 방식을 채택합니다. 따라서 웹 호스팅이 간편하고 빠르며 보안성이 높습니다."
  },
  {
    "objectID": "posts/netlify-deployment/netlify-deployment.html#netlify-쉬운가요",
    "href": "posts/netlify-deployment/netlify-deployment.html#netlify-쉬운가요",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "Netlify 쉬운가요?",
    "text": "Netlify 쉬운가요?\n네!\n다음과 같은 설정 1번만 해 두면, 블로그에 새 글을 추가하거나 변경하는 내용이 자동으로 배포됩니다. 이를 지속적 배포(continuous deployment) 라고 합니다. 이런 기술적 용어나 원리는 몰라도 됩니다. Netlify 서비스가 모든 것을 관리해 주니까요.\n여러분이 할 일은 Quarto로 만든 블로그 작성 프로젝트를 깃헙에 연동한 뒤, Netlify에 해당 깃헙을 연결하는 설정 1번만 하는 것이에요.\n해외 서비스라서 모든 기능이 영어로만 제공된다는 것이 조금 불편할 수 있지만, 구글 번역기 등을 활용해서 충분히"
  },
  {
    "objectID": "posts/netlify-deployment/netlify-deployment.html#깃헙---netlify-연결하기",
    "href": "posts/netlify-deployment/netlify-deployment.html#깃헙---netlify-연결하기",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "깃헙 - Netlify 연결하기",
    "text": "깃헙 - Netlify 연결하기\nQuarto 블로그 프로젝트를 깃헙에 연결하는 방법은 이 블로그 포스팅 도입부에 소개한 R Quarto로 블로그 만들기 글을 참고해 주세요. 여기서는 깃헙 연동에 성공한 이후 Netlify 연결 방법에 관해 소개합니다.\n\n(1) Netlify 계정 만들기\nNetlify 바로가기\n처음 시작하는 계정은 무료 입니다. 추후 블로그 방문자 트래픽이 커지면 비용이 발생할 수 있지만, 대부분의 개인 블로그 정도는 무료로 운영 가능합니다. 무료 계정 허용 용량 이상 트래픽은 로그인 후 제공하는 대시보드 형태 화면에서 확인 가능 합니다.\n신규 계정 만들 때는 깃헙 계정을 연동하는 방식을 추천 합니다. 어차피 우리가 배포하려는 서비스가 깃헙에 등록되어 있기 때문에 다른 이메일 주소로 가입하더라도 깃헙 계정과 연동을 해야 하긴 합니다.\n\n\n(2) 깃헙 레포지토리 불러오기\n\n로그인 후 보이는 화면에서 Add new site 클릭\nImport an existing project 선택\nDeploy with GitHub 선택\n깃헙 계정과 연동 허용\nNetlify에서 배포할 레포지토리를 선택\n\n\n\n\n등록할 깃헙 레포지토리 설정하는 방법\n\n\n\n\n(3) 사이트 이름 지정\n\n기본적으로 xxxx.netlify.app 이라는 홈페이지 주소가 자동 부여됩니다.\nSite name에 내가 원하는 서브 도메인 이름을 영어로 작성하여 사용 가능 여부를 확인 합니다.\n\n이 단계에서 놓쳐도 설정에서 변경할 수 있어요.\n\n\n\n\n\n사이트명 설정하기\n\n\n\n\n(4) (가장 중요) 배포 폴더 지정\n\nBuild settings &gt; Publish directory 에서 _site 라고 입력합니다.\n\n이 옵션은 Quarto 블로그 프로젝트를 생성했다면 공통 적용 입니다.\n\n다른 것은 수정하거나 추가하지 마세요.\nDeploy XXX (배포할 레포지토리 이름) 버튼 클릭하세요\n\n\n\n\n_site 라고 입력하기\n\n\n여기까지 5분 정도 걸리셨나요? 모든 설정이 끝났어요. 진짜로요."
  },
  {
    "objectID": "posts/netlify-deployment/netlify-deployment.html#이제-블로그-쓰기만-하세요",
    "href": "posts/netlify-deployment/netlify-deployment.html#이제-블로그-쓰기만-하세요",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "이제 블로그 쓰기만 하세요",
    "text": "이제 블로그 쓰기만 하세요\n지금 여러분이 보고 있는 Mindful Analytics 블로그도 바로 Quarto-GitHub-Netlify 조합으로 만들고 배포 하였습니다. 이 연동 설정은 1회만 하면 됩니다. 앞으로는 Quarto로 추가 포스팅 작성 후 GitHub로 커밋 & 푸쉬만 하면 Netlify가 해당 변경 내용을 실시간으로 받아서 웹사이트를 상시 업데이트 해 줍니다. 변경에 대한 배포에 대해 고민할 필요가 없는 것이 Netlify를 쓰는 가장 큰 장점 이에요.\n\n(보너스) 연동 후 새로운 글 배포하는 방법\n\nposts 폴더 안에 새로운 블로그 글을 작성할 폴더를 만듭니다.\n\n작성할 포스트 제목을 나타내는 키워드를 영어로 골라서 폴더명을 쓰세요.\n예를 들어, 제가 작성 중인 이 포스트는 netlify-deployment 폴더 안에 있습니다.\n이 폴더 이름이 블로그 글 주소에 들어가게 됩니다.\n\n새로 만든 폴더 안에 .qmd 파일을 생성하고 블로그 템플릿을 참고하여 새 글을 작성합니다.\n\n추가할 그림이나 데이터는 이 폴더 안에 함께 담아 주면 별도 경로 지정할 필요가 없어요.\n\n글 작성 후 웹 등록하려면 다음 2가지를 꼭 기억하세요.\n\n블로그 .qmd의 yaml 헤더에 draft: false 인지 꼭 확인하세요 (삭제하면 더 좋아요)\n다 작성한 뒤 반드시 Render를 해서 html 파일을 생성합니다. 변경 사항 저장 시 자동 Render 되도록 Render on Save 옵션을 활성화하면 편리합니다.\n_site 폴더 안에 내가 만든 포스팅 폴더가 추가 되었는지 확인하세요\n\n깃헙에 변경된 내용을 커밋 & 푸쉬하는 것 잊지 마세요.\n\n\n여러분도 R로 쓰는 블로그, Quarto-GitHub-Netlify 조합으로 쉽고 빠르게 만들어 나가시길 바랍니다.\n\n\n\nArtwork by Allison Horst\n등록할 깃헙 레포지토리 설정하는 방법\n사이트명 설정하기\n_site 라고 입력하기"
  },
  {
    "objectID": "posts/netlify-deployment/netlify-deployment.html#footnotes",
    "href": "posts/netlify-deployment/netlify-deployment.html#footnotes",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n정적 웹사이트란 미리 웹 페이지 내용이 생성되어 서버에서 사용자 요청에 따라 생성되거나 처리되는 컨텐츠가 없는 사이트 입니다.↩︎"
  },
  {
    "objectID": "featured.html",
    "href": "featured.html",
    "title": "Featured",
    "section": "",
    "text": "Quarto 블로그 SEO 최적화 3가지 꿀팁\n\n\n2 min\n\n\n\nfeatured\n\n\nquarto\n\n\nR\n\n\nseo\n\n\n\n\n박세희\n\n\n2024-03-14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndbplyr로 bigquery 데이터 추출하기\n\n\n4 min\n\n\n\nfeatured\n\n\nbigquery\n\n\nR\n\n\ndbplyr\n\n\nsql\n\n\n\n\n박세희\n\n\n2024-03-14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR에서 구글빅쿼리 데이터 추출하기\n\n\n4 min\n\n\n\nfeatured\n\n\nbigquery\n\n\nsql\n\n\nR\n\n\n\n\n박세희\n\n\n2024-02-26\n\n\n\n\n\n\n\n\n\n\n\n\nR Quarto로 만든 블로그 배포(feat. Netlify)\n\n\n4 min\n\n\n\nfeatured\n\n\ngit\n\n\nquarto\n\n\nnetlify\n\n\n\n\n박세희\n\n\n2024-02-24\n\n\n\n\n\n\n\n\n\n\n\n\nR Quarto로 만드는 블로그\n\n\n5 min\n\n\n\nfeatured\n\n\ngit\n\n\nquarto\n\n\nR\n\n\n\n\n박세희\n\n\n2024-02-23\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/bigquery-r/bigquery-r.html",
    "href": "posts/bigquery-r/bigquery-r.html",
    "title": "R에서 구글빅쿼리 데이터 추출하기",
    "section": "",
    "text": "언제 읽으면 좋을까?\n\n\n\n\n구글빅쿼리 데이터를 RStudio에서 받아오고 싶을 때\n\n구글빅쿼리와 RStudio 연결 방법을 모를 때\n\nbigrquery 패키지 사용법을 알고 싶을 때"
  },
  {
    "objectID": "posts/bigquery-r/bigquery-r.html#bigrquery-패키지",
    "href": "posts/bigquery-r/bigquery-r.html#bigrquery-패키지",
    "title": "R에서 구글빅쿼리 데이터 추출하기",
    "section": "bigrquery 패키지",
    "text": "bigrquery 패키지\nbigrquery 패키지는 가벼운 API 연동으로 빅쿼리에 저장된 데이터 정보(메타데이터)를 빠르게 받아올 수 있습니다.\n\n(1) 패키지 설치하기\n\ninstall.packages(\"bigrquery\")\nlibrary(bigrquery)\n\n\n\n(2) 계정 인증\n다음 명령을 실행하면 웹 브라우저가 열리면서 구글 계정에 로그인하도록 안내가 됩니다. 계정 연결은 최초 1회만 필요합니다.\n\nbigrquery::bq_auth()\n\n\n\n\n빅쿼리 계정 인증 필요\n\n\n\n\n(3) 공개 데이터셋 정보 확인\n공개 데이터셋 정보는 다음과 같습니다.\n\n프로젝트: “bigquery-public-data”\n\n데이터셋: “samples”\n\n데이터셋 안에 어떤 테이블이 존재하는지 모를 경우, bq_dataset(\"프로젝트명\", \"데이터셋명\") 명령을 실행하여 확인 합니다.\n\nds_sample &lt;- bigrquery::bq_dataset(\"bigquery-public-data\", \"samples\")\nprint(ds_sample)\n\n&lt;bq_dataset&gt; bigquery-public-data.samples\n\n\n데이터에 관한 정보, 즉 메타데이터를 추출하기 때문에 “프로젝트명.데이터셋명”으로 정의된 데이터가 있다고 확인 메세지를 출력합니다.\n데이터셋에 어떤 테이블이 들어 있는지 확인하려면, bq_dataset_tables(\"프로젝트명\", \"데이터셋명\") 명령을 실행 합니다. 여기서는 해당 정보를 ds_samples_tables 변수에 저장합니다.\nds_samples_tables에서 메타데이터 정보를 추출하면 총 7개의 테이블이 있는 것을 알 수 있습니다. 구글 빅쿼리 홈페이지에서 확인했던 7개 테이블과 동일한 정보 입니다.\n테이블 이름은 “프로젝트.데이터셋.테이블”으로 표시됩니다.\n\nds_samples_tables &lt;- bigrquery::bq_dataset_tables(ds_sample) \nprint(ds_samples_tables)\n\n[[1]]\n&lt;bq_table&gt; bigquery-public-data.samples.github_nested\n\n[[2]]\n&lt;bq_table&gt; bigquery-public-data.samples.github_timeline\n\n[[3]]\n&lt;bq_table&gt; bigquery-public-data.samples.gsod\n\n[[4]]\n&lt;bq_table&gt; bigquery-public-data.samples.natality\n\n[[5]]\n&lt;bq_table&gt; bigquery-public-data.samples.shakespeare\n\n[[6]]\n&lt;bq_table&gt; bigquery-public-data.samples.trigrams\n\n[[7]]\n&lt;bq_table&gt; bigquery-public-data.samples.wikipedia\n\n\n\n\n(4) 분석 데이터 선택\n7개 테이블 중 natality 테이블을 선택합니다. bq_table(프로젝트, 데이터셋, 테이블) 명령을 실행하면 해당 테이블에 대한 메타 정보를 출력합니다.\n\nnatality &lt;- bigrquery::bq_table(\"bigquery-public-data\", \"samples\", \"natality\")\nprint(natality)\n\n&lt;bq_table&gt; bigquery-public-data.samples.natality\n\n\n\n\n(5) 빅쿼리 비용 주의사항\n메타데이터는 실제 해당 테이블이 가지고 있는 데이터를 포함하지 않고 단순히 어떤 프로젝트, 데이터셋, 테이블 인지를 정의한 정보 입니다. 데이터를 출력하려면 bq_table_download()를 사용합니다. 이 때 서버에 얼마나 많은 양의 데이터가 있는지 알 수 없기 때문에 모든 데이터를 출력하지 않아야 합니다. 자칫 실수로 전체 데이터를 받을 경우 과도한 비용과 서버 과부하가 발생합니다.\n또한 빅쿼리는 데이터를 “열(column)”을 기준으로 저장합니다. 따라서 열을 조회하는 순간 행(row) 갯수와 관계없이 비용이 부과됩니다.\n빅쿼리는 데이터 저장 비용은 매우 저렴하지만, 데이터를 조회(SELECT)하거나 추출할 때 비용이 발생하기 때문에 sql 쿼리 설계를 잘 해야 운영 비용이 적게 발생합니다.\n따라서 다음과 같이 테이블이 가진 첫 6개 행을 출력하는 것은 비용 절감에 도움이 되지 않습니다.\n첫 6개행 출력하기\n\nnatality_df &lt;- bigrquery::bq_table_download(natality, n_max = 6)\nprint(natality_df)\n\n\n\n\n\n\n\n차라리 출력하는 열 갯수를 줄이는 것이 비용을 많이 절약할 수 있습니다. R에서는 실제 sql 문구를 적용하기 전에는 데이터 양이 얼마나 될 지 미리 알 수가 없습니다. 따라서 빅쿼리 초보 사용자라면 구글 빅쿼리 콘솔에서 실제로 SQL 구문을 수정해 보면서 데이터 양을 비교해 보는 것을 추천합니다.\n\nnatality 테이블 모든 열을 조회하는 경우: 데이터 용량 21.94GB\n\n\n\n\n모든 열 1000개 행 조회 시 용량\n\n\n\nnatality 테이블 중 3개 열에 한정하여 조회하는 경우: 데이터 용량 2.11GB (1/10 정도로 줄었습니다)\n\n\n\n\n3개 열 1000개 행 조회 시 용량\n\n\n\nnatality 테이블 중 3개 열의 행 추출 수를 제한하지 않아도(LIMIT 1000 삭제) 데이터 용량은 2.11 GB로 동일합니다.\n\n\n\n\n3개 열 모든 행 조회 시 용량\n\n\n\n오늘은 R에서 빅쿼리 데이터에 접근해서 데이터를 다운로드하는 기초적인 방법을 알아 봤습니다. 다음 글에서는 필요한 열(column) 정보와 행(row) 정보를 선택할 수 있도록 SQL 코드를 R dplyr 패키지와 유사하게 구현할 수 있는 dbplyr 패키지를 활용해서 효율적인 빅쿼리 데이터 다운로드 방법에 관해 소개하겠습니다.\n\n빅쿼리에 저장된 GA4 데이터를 가장 효율적인 분석 언어 R로 추출해 보세요.\n\n\n\n\n빅쿼리 계정 인증 필요\n모든 열 1000개 행 조회 시 용량\n3개 열 1000개 행 조회 시 용량\n3개 열 모든 행 조회 시 용량"
  },
  {
    "objectID": "posts/bigquery-r/bigquery-r.html#구글-빅쿼리bigquery란",
    "href": "posts/bigquery-r/bigquery-r.html#구글-빅쿼리bigquery란",
    "title": "R에서 구글빅쿼리 데이터 추출하기",
    "section": "1. 구글 빅쿼리(BigQuery)란?",
    "text": "1. 구글 빅쿼리(BigQuery)란?\n구글 빅쿼리는 대용량 데이터를 효율적으로 처리하고 분석할 수 있도록 구글에서 제공하는 온라인 데이터베이스 서비스 입니다. 특히 온라인 고객 행동을 모니터링하기 위해 사용하는 GA4(구글애널리틱스4) 데이터를 빅쿼리로 바로 연동하도록 설계되어 있습니다. 이 때문에 GA4 데이터 분석에서는 빅쿼리 사용 점점 늘어나고 있기도 합니다.\n빅쿼리는 많은 양의 데이터를 온라인에서 분석할 수 있도록 쥬피터노트북과 연계되어 있기 때문에 데이터를 다운로드 하는 것 보다는 온라인에서 직접 분석하는 게 더 효율적일 수 있습니다. 그럼에도 불구하고 데이터를 다운로드 받아서 로컬에서 분석해야 하는 경우, bigrquery 패키지를 활용하여 데이터를 다운로드 할 수도 있습니다."
  },
  {
    "objectID": "posts/bigquery-r/bigquery-r.html#빅쿼리-시작하기",
    "href": "posts/bigquery-r/bigquery-r.html#빅쿼리-시작하기",
    "title": "R에서 구글빅쿼리 데이터 추출하기",
    "section": "2. 빅쿼리 시작하기",
    "text": "2. 빅쿼리 시작하기\n\n\n\n\n\n\n빅쿼리 설정 먼저\n\n\n\n구글 빅쿼리에 계정과 데이터를 추가한 뒤에 R에서 연결합니다.\n* 계정 만들기\n* 계정에 공개 데이터셋 추가하기\n\n\n\n(1) 빅쿼리 계정 만들기\n빅쿼리 홈페이지를 방문하여 본인의 구글 계정에서 빅쿼리를 사용할 수 있도록 가입합니다. 빅쿼리 시작 시에는 무료이며, 300$의 무료 크레딧이 제공됩니다. 데이터를 불러올 때 용량에 따라 크레딧이 차감되고, 크레딧을 소진하는 경우 추가 비용이 발생할 수 있습니다.\n빅쿼리 계정을 만들면 콘솔(대시보드)가 생성됩니다.\n\n\n(2) 빅쿼리 계정에 공개 데이터셋 추가하기\nbigrquery 설치 후 예제를 수행하기 위해서는 본인의 구글 계정에 테스트용 공개 데이터셋를 먼저 추가해야 합니다. 추가하는 방법은 다음과 같습니다.\n\n빅쿼리 콘솔 &gt; 탐색기(Explorer) &gt; +추가 버튼 클릭\n\n새 창에서 “public data”로 검색 &gt; Public datasets 선택\n\n필터에서 분석, 데이터, 무료 선택 &gt; ‘Google’s diversity annual report data’ 선택: 이 때 무엇을 선택해도 상관없이 나의 데이터 목록에 bigquery-public-data 프로젝트가 추가 됩니다.\n\nbigquery-public-data 프로젝트를 클릭하면 수 많은 데이터 목록이 보이는데, 그 중에 “samples”라는 데이터셋을 테스트 하겠습니다.\n\n\n\n\n(3) 빅쿼리 데이터 구조\n빅쿼리는 프로젝트 &gt; 데이터셋 &gt; 테이블 3단 구조로 설계되어 있습니다. 분석용 데이터는 테이블에 저장되어 있습니다. 우리에게 친숙한 엑셀과 비교하자면, 데이터셋은 파일, 테이블은 시트와 유사한 구조입니다.\n빅쿼리 접속할 경우에 이 3가지 정보를 정확히 입력해야 원하는 데이터를 받을 수 있습니다."
  },
  {
    "objectID": "posts/bigquery-r/bigquery-r.html#유용한-패키지",
    "href": "posts/bigquery-r/bigquery-r.html#유용한-패키지",
    "title": "R에서 구글빅쿼리 데이터 분석하기",
    "section": "유용한 패키지",
    "text": "유용한 패키지\n\n(1) birgquery\nbigrquery 패키지는 가벼운 API 연동으로 빅쿼리에 저장된 데이터 정보(메타데이터)를 빠르게 받아올 수 있습니다.\n\n(a) 패키지 설치하기\n\ninstall.packages(\"bigrquery\")\nlibrary(bigrquery)\n\n\n\n(b) 계정 인증\n다음 명령을 실행하면 웹 브라우저가 열리면서 구글 계정에 로그인하도록 안내가 됩니다. 계정 연결은 최초 1회만 필요합니다.\n\nbigrquery::bq_auth()\n\n\n\n\n빅쿼리 계정 인증 필요\n\n\n\n\n(c) 공개 데이터셋 정보 확인\n공개 데이터셋 정보는 다음과 같습니다.\n\n프로젝트: “bigquery-public-data”\n\n데이터셋: “samples”\n\n데이터셋 안에 어떤 테이블이 존재하는지 모를 경우, bq_dataset(\"프로젝트명\", \"데이터셋명\") 명령을 실행하여 확인 합니다.\n\nds_sample &lt;- bigrquery::bq_dataset(\"bigquery-public-data\", \"samples\")\nprint(ds_sample)\n\n&lt;bq_dataset&gt; bigquery-public-data.samples\n\n\n데이터에 관한 정보, 즉 메타데이터를 추출하기 때문에 “프로젝트명.데이터셋명”으로 정의된 데이터가 있다고 확인 메세지를 출력합니다.\n데이터셋에 어떤 테이블이 들어 있는지 확인하려면, bq_dataset_tables(\"프로젝트명\", \"데이터셋명\") 명령을 실행 합니다. 여기서는 해당 정보를 ds_samples_tables 변수에 저장합니다.\nds_samples_tables에서 메타데이터 정보를 추출하면 총 7개의 테이블이 있는 것을 알 수 있습니다. 구글 빅쿼리 홈페이지에서 확인했던 7개 테이블과 동일한 정보 입니다.\n테이블 이름은 “프로젝트.데이터셋.테이블”으로 표시됩니다.\n\nds_samples_tables &lt;- bigrquery::bq_dataset_tables(ds_sample) \nprint(ds_samples_tables)\n\n[[1]]\n&lt;bq_table&gt; bigquery-public-data.samples.github_nested\n\n[[2]]\n&lt;bq_table&gt; bigquery-public-data.samples.github_timeline\n\n[[3]]\n&lt;bq_table&gt; bigquery-public-data.samples.gsod\n\n[[4]]\n&lt;bq_table&gt; bigquery-public-data.samples.natality\n\n[[5]]\n&lt;bq_table&gt; bigquery-public-data.samples.shakespeare\n\n[[6]]\n&lt;bq_table&gt; bigquery-public-data.samples.trigrams\n\n[[7]]\n&lt;bq_table&gt; bigquery-public-data.samples.wikipedia\n\n\n\n\n(d) 분석 데이터 선택\n7개 테이블 중 natality 테이블을 선택합니다. bq_table(프로젝트, 데이터셋, 테이블) 명령을 실행하면 해당 테이블에 대한 메타 정보를 출력합니다.\n\nnatality &lt;- bigrquery::bq_table(\"bigquery-public-data\", \"samples\", \"natality\")\nprint(natality)\n\n&lt;bq_table&gt; bigquery-public-data.samples.natality\n\n\n\n\n(e) 주의사항\n메타데이터는 실제 해당 테이블이 가지고 있는 데이터를 포함하지 않고 단순히 어떤 프로젝트, 데이터셋, 테이블 인지를 정의한 정보 입니다. 데이터를 출력하려면 bq_table_download()를 사용합니다. 이 때 서버에 얼마나 많은 양의 데이터가 있는지 알 수 없기 때문에 모든 데이터를 출력하지 않아야 합니다. 자칫 실수로 전체 데이터를 받을 경우 과도한 비용과 서버 과부하가 발생합니다.\n따라서 다음과 같이 테이블이 가진 첫 6개 행을 출력해 보는 것을 습관화 하는 것이 좋겠습니다.\n첫 10개행 출력하기\n\nnatality_df &lt;- bigrquery::bq_table_download(natality, n_max = 6)\nprint(natality_df)\n\n\n\n\n\n\n\n\n\n\n(2) dbplyr\n\n\n\n빅쿼리 계정 인증 필요"
  },
  {
    "objectID": "posts/bigquery-r/bigquery-r.html#birgquery-패키지",
    "href": "posts/bigquery-r/bigquery-r.html#birgquery-패키지",
    "title": "R에서 구글빅쿼리 데이터 추출하기",
    "section": "birgquery 패키지",
    "text": "birgquery 패키지\nbigrquery 패키지는 가벼운 API 연동으로 빅쿼리에 저장된 데이터 정보(메타데이터)를 빠르게 받아올 수 있습니다.\n\n(a) 패키지 설치하기\n\ninstall.packages(\"bigrquery\")\nlibrary(bigrquery)\n\n\n\n(b) 계정 인증\n다음 명령을 실행하면 웹 브라우저가 열리면서 구글 계정에 로그인하도록 안내가 됩니다. 계정 연결은 최초 1회만 필요합니다.\n\nbigrquery::bq_auth()\n\n\n\n\n빅쿼리 계정 인증 필요\n\n\n\n\n(c) 공개 데이터셋 정보 확인\n공개 데이터셋 정보는 다음과 같습니다.\n\n프로젝트: “bigquery-public-data”\n\n데이터셋: “samples”\n\n데이터셋 안에 어떤 테이블이 존재하는지 모를 경우, bq_dataset(\"프로젝트명\", \"데이터셋명\") 명령을 실행하여 확인 합니다.\n\nds_sample &lt;- bigrquery::bq_dataset(\"bigquery-public-data\", \"samples\")\nprint(ds_sample)\n\n&lt;bq_dataset&gt; bigquery-public-data.samples\n\n\n데이터에 관한 정보, 즉 메타데이터를 추출하기 때문에 “프로젝트명.데이터셋명”으로 정의된 데이터가 있다고 확인 메세지를 출력합니다.\n데이터셋에 어떤 테이블이 들어 있는지 확인하려면, bq_dataset_tables(\"프로젝트명\", \"데이터셋명\") 명령을 실행 합니다. 여기서는 해당 정보를 ds_samples_tables 변수에 저장합니다.\nds_samples_tables에서 메타데이터 정보를 추출하면 총 7개의 테이블이 있는 것을 알 수 있습니다. 구글 빅쿼리 홈페이지에서 확인했던 7개 테이블과 동일한 정보 입니다.\n테이블 이름은 “프로젝트.데이터셋.테이블”으로 표시됩니다.\n\nds_samples_tables &lt;- bigrquery::bq_dataset_tables(ds_sample) \nprint(ds_samples_tables)\n\n[[1]]\n&lt;bq_table&gt; bigquery-public-data.samples.github_nested\n\n[[2]]\n&lt;bq_table&gt; bigquery-public-data.samples.github_timeline\n\n[[3]]\n&lt;bq_table&gt; bigquery-public-data.samples.gsod\n\n[[4]]\n&lt;bq_table&gt; bigquery-public-data.samples.natality\n\n[[5]]\n&lt;bq_table&gt; bigquery-public-data.samples.shakespeare\n\n[[6]]\n&lt;bq_table&gt; bigquery-public-data.samples.trigrams\n\n[[7]]\n&lt;bq_table&gt; bigquery-public-data.samples.wikipedia\n\n\n\n(d) 분석 데이터 선택\n7개 테이블 중 natality 테이블을 선택합니다. bq_table(프로젝트, 데이터셋, 테이블) 명령을 실행하면 해당 테이블에 대한 메타 정보를 출력합니다.\n\nnatality &lt;- bigrquery::bq_table(\"bigquery-public-data\", \"samples\", \"natality\")\nprint(natality)\n\n&lt;bq_table&gt; bigquery-public-data.samples.natality\n\n\n\n\n\n(e) 주의사항\n메타데이터는 실제 해당 테이블이 가지고 있는 데이터를 포함하지 않고 단순히 어떤 프로젝트, 데이터셋, 테이블 인지를 정의한 정보 입니다. 데이터를 출력하려면 bq_table_download()를 사용합니다. 이 때 서버에 얼마나 많은 양의 데이터가 있는지 알 수 없기 때문에 모든 데이터를 출력하지 않아야 합니다. 자칫 실수로 전체 데이터를 받을 경우 과도한 비용과 서버 과부하가 발생합니다.\n따라서 다음과 같이 테이블이 가진 첫 6개 행을 출력해 보는 것을 습관화 하는 것이 좋겠습니다.\n첫 6개행 출력하기\n\nnatality_df &lt;- bigrquery::bq_table_download(natality, n_max = 6)\nprint(natality_df)\n\n\n\n\n\n\n\n\n오늘은 R에서 빅쿼리 데이터에 접근해서 데이터를 다운로드하는 기초적인 방법을 알아 봤습니다. 다음 글에서는 필요한 열(column) 정보와 행(row) 정보를 선택할 수 있도록 SQL 코드를 R dplyr 패키지와 유사하게 구현할 수 있는 dbplyr 패키지를 활용해서 효율적인 빅쿼리 데이터 다운로드 방법에 관해 소개하겠습니다.\n\n빅쿼리에 저장된 GA4 데이터를 가장 효율적인 분석 언어 R로 추출해 보세요.\n\n\n\n\n빅쿼리 계정 인증 필요"
  },
  {
    "objectID": "posts/bigquery-r/bigquery-r.html#bigrquery-패키지-활용법",
    "href": "posts/bigquery-r/bigquery-r.html#bigrquery-패키지-활용법",
    "title": "R에서 구글빅쿼리 데이터 추출하기",
    "section": "3. bigrquery 패키지 활용법",
    "text": "3. bigrquery 패키지 활용법\nbigrquery 패키지는 가벼운 API 연동으로 빅쿼리에 저장된 데이터 정보(메타데이터)를 빠르게 받아올 수 있습니다.\n\n(1) 패키지 설치하기\n\ninstall.packages(\"bigrquery\")\nlibrary(bigrquery)\n\n\n\n(2) 계정 인증\n다음 명령을 실행하면 웹 브라우저가 열리면서 구글 계정에 로그인하도록 안내가 됩니다. 계정 연결은 최초 1회만 필요합니다.\n\nbigrquery::bq_auth()\n\n\n\n\n빅쿼리 계정 인증 필요\n\n\n\n\n(3) 공개 데이터셋 정보 확인\n공개 데이터셋 정보는 다음과 같습니다.\n\n프로젝트: “bigquery-public-data”\n\n데이터셋: “samples”\n\n데이터셋 안에 어떤 테이블이 존재하는지 모를 경우, bq_dataset(\"프로젝트명\", \"데이터셋명\") 명령을 실행하여 확인 합니다.\n\nds_sample &lt;- bigrquery::bq_dataset(\"bigquery-public-data\", \"samples\")\nprint(ds_sample)\n\n&lt;bq_dataset&gt; bigquery-public-data.samples\n\n\n데이터에 관한 정보, 즉 메타데이터를 추출하기 때문에 “프로젝트명.데이터셋명”으로 정의된 데이터가 있다고 확인 메세지를 출력합니다.\n데이터셋에 어떤 테이블이 들어 있는지 확인하려면, bq_dataset_tables(\"프로젝트명\", \"데이터셋명\") 명령을 실행 합니다. 여기서는 해당 정보를 ds_samples_tables 변수에 저장합니다.\nds_samples_tables에서 메타데이터 정보를 추출하면 총 7개의 테이블이 있는 것을 알 수 있습니다. 구글 빅쿼리 홈페이지에서 확인했던 7개 테이블과 동일한 정보 입니다.\n테이블 이름은 “프로젝트.데이터셋.테이블”으로 표시됩니다.\n\nds_samples_tables &lt;- bigrquery::bq_dataset_tables(ds_sample) \nprint(ds_samples_tables)\n\n[[1]]\n&lt;bq_table&gt; bigquery-public-data.samples.github_nested\n\n[[2]]\n&lt;bq_table&gt; bigquery-public-data.samples.github_timeline\n\n[[3]]\n&lt;bq_table&gt; bigquery-public-data.samples.gsod\n\n[[4]]\n&lt;bq_table&gt; bigquery-public-data.samples.natality\n\n[[5]]\n&lt;bq_table&gt; bigquery-public-data.samples.shakespeare\n\n[[6]]\n&lt;bq_table&gt; bigquery-public-data.samples.trigrams\n\n[[7]]\n&lt;bq_table&gt; bigquery-public-data.samples.wikipedia\n\n\n\n\n(4) 분석 데이터 선택\n7개 테이블 중 natality 테이블을 선택합니다. bq_table(프로젝트, 데이터셋, 테이블) 명령을 실행하면 해당 테이블에 대한 메타 정보를 출력합니다.\n\nnatality &lt;- bigrquery::bq_table(\"bigquery-public-data\", \"samples\", \"natality\")\nprint(natality)\n\n&lt;bq_table&gt; bigquery-public-data.samples.natality\n\n\n\n\n(5) 빅쿼리 비용 주의사항\n메타데이터는 실제 해당 테이블이 가지고 있는 데이터를 포함하지 않고 단순히 어떤 프로젝트, 데이터셋, 테이블 인지를 정의한 정보 입니다. 데이터를 출력하려면 bq_table_download()를 사용합니다. 이 때 서버에 얼마나 많은 양의 데이터가 있는지 알 수 없기 때문에 모든 데이터를 출력하지 않아야 합니다. 자칫 실수로 전체 데이터를 받을 경우 과도한 비용과 서버 과부하가 발생합니다.\n또한 빅쿼리는 데이터를 “열(column)”을 기준으로 저장합니다. 따라서 열을 조회하는 순간 행(row) 갯수와 관계없이 비용이 부과됩니다.\n빅쿼리는 데이터 저장 비용은 매우 저렴하지만, 데이터를 조회(SELECT)하거나 추출할 때 비용이 발생하기 때문에 sql 쿼리 설계를 잘 해야 운영 비용이 적게 발생합니다.\n따라서 다음과 같이 테이블이 가진 첫 6개 행을 출력하는 것은 비용 절감에 도움이 되지 않습니다.\n첫 6개행 출력하기\n\nnatality_df &lt;- bigrquery::bq_table_download(natality, n_max = 6)\nprint(natality_df)\n\n\n\n\n\n\n\n차라리 출력하는 열 갯수를 줄이는 것이 비용을 많이 절약할 수 있습니다. R에서는 실제 sql 문구를 적용하기 전에는 데이터 양이 얼마나 될 지 미리 알 수가 없습니다. 따라서 빅쿼리 초보 사용자라면 구글 빅쿼리 콘솔에서 실제로 SQL 구문을 수정해 보면서 데이터 양을 비교해 보는 것을 추천합니다.\n\nnatality 테이블 모든 열을 조회하는 경우: 데이터 용량 21.94GB\n\n\n\n\n모든 열 1000개 행 조회 시 용량\n\n\n\nnatality 테이블 중 3개 열에 한정하여 조회하는 경우: 데이터 용량 2.11GB (1/10 정도로 줄었습니다)\n\n\n\n\n3개 열 1000개 행 조회 시 용량\n\n\n\nnatality 테이블 중 3개 열의 행 추출 수를 제한하지 않아도(LIMIT 1000 삭제) 데이터 용량은 2.11 GB로 동일합니다.\n\n\n\n\n3개 열 모든 행 조회 시 용량\n\n\n\n오늘은 R에서 빅쿼리 데이터에 접근해서 데이터를 다운로드하는 기초적인 방법을 알아 봤습니다. 다음 글에서는 필요한 열(column) 정보와 행(row) 정보를 선택할 수 있도록 SQL 코드를 R dplyr 패키지와 유사하게 구현할 수 있는 dbplyr 패키지를 활용해서 효율적인 빅쿼리 데이터 다운로드 방법에 관해 소개하겠습니다.\n\n빅쿼리에 저장된 GA4 데이터를 가장 효율적인 분석 언어 R로 추출해 보세요.\n\n\n\n\n빅쿼리 계정 인증 필요\n모든 열 1000개 행 조회 시 용량\n3개 열 1000개 행 조회 시 용량\n3개 열 모든 행 조회 시 용량"
  },
  {
    "objectID": "posts/bigquery-dbplyr/bigquery-dbplyr.html",
    "href": "posts/bigquery-dbplyr/bigquery-dbplyr.html",
    "title": "dbplyr로 bigquery 데이터 추출하기",
    "section": "",
    "text": "누가, 언제 읽으면 좋을까?\n\n\n\n\ntidyverse 문법에 익숙한 R 사용자가\n\nSQL 구문을 사용하지 않고 빅쿼리 데이터를 추출하고 싶을 때"
  },
  {
    "objectID": "posts/bigquery-dbplyr/bigquery-dbplyr.html#dbplyr-소개",
    "href": "posts/bigquery-dbplyr/bigquery-dbplyr.html#dbplyr-소개",
    "title": "dbplyr로 bigquery 데이터 추출하기",
    "section": "1. dbplyr 소개",
    "text": "1. dbplyr 소개\ndbplyr은 tidyverse 패키지 중 하나로, 데이터베이스에서 데이터를 추출하는 패키지입니다. dbplyr은 R사용자에게 익숙한 dplyr 문법으로 사용하여 *SQL을 사용하지 않고도 데이터베이스에서 데이터를 추출할 수 있게 해 줍니다.\ndbplyr 패키지에서 가장 많이 활용되는 함수는 tbl() 함수로, 데이터베이스에서 테이블을 불러올 때 사용합니다. tbl() 함수를 사용하면 데이터베이스에서 테이블을 불러올 때 사용하는 SQL문을 사용하지 않고도 데이터를 불러올 수 있습니다.\n\n(1) 사용 패키지 설치\n\n# dbplyr을 포함한 tidyverse 패키지를 설치하고 실행합니다. \ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n# 구글빅쿼리 접속을 위한 bigrquery 패키지를 설치하고 실행합니다.\ninstall.packages(\"bigrquery\")\nlibrary(bigrquery)\n\n\n\n(2) 빅쿼리 계정 연결하기\n구글 빅쿼리에 접속하여 이 글에서 사용하는 공개 데이터셋을 활용하려면 빅쿼리 계정이 필요합니다. 빅쿼리 계정 설정 방법은 ‘R에서 구글빅쿼리 데이터 추출하기’를 참고하세요. 계정 설정이 끝났다면 아래 코드를 실행하여 빅쿼리 접속 권한을 설정합니다.\n\n# 계정 연결하기 \nbigrquery::bq_auth()\n\n\n\n(3) 데이터베이스 연결하기\nbigrquery 패키지를 사용하여 구글 빅쿼리에 연결합니다. 연결을 위해서는 dbConnect() 함수를 사용합니다.\n빅쿼리 계정이 준비되었다면, dbConnect() 함수를 사용하여 데이터베이스에 연결합니다.\n\n# 데이터베이스 연결하기 \ncon &lt;- DBI::dbConnect(\n  bigrquery::bigquery(),\n  project = \"bigquery-public-data\",\n  dataset = \"samples\",\n  billing = \"여기에 본인 계정 프로젝트 이름을 넣습니다\"\n)\n\n데이터베이스 연결이 성공하면 con 객체에 데이터베이스 연결 정보가 저장됩니다. 연결이 되었다면, 다음 이미지처럼 RStudio &gt; Connections 탭에서 연결된 데이터베이스가 갖고 있는 테이블 정보를 확인할 수 있습니다.\n\n\n\n빅쿼리 공개데이터 테이블셋 리스트\n\n\n이 글에서는 shakespeare 테이블을 사용하겠습니다.\n\n\n(4) 테이블 불러오기\ntbl() 함수를 사용하여 데이터베이스에서 테이블을 불러올 수 있습니다. shakespeare 테이블을 불러 오겠습니다. 이 때 테이블 데이터가 실제 다운로드 되지 않고, 데이터베이스에 있는 테이블 메타 정보만을 불러옵니다. 이렇게 tbl() 함수를 사용하여 데이터 정보를 보는 것은 데이터 다운로드 비용 발생 없이 테이블 내용을 살펴보기 용이한 빅쿼리 활용 방법입니다.\n\n# 테이블 불러오기    \ndb_table &lt;- tbl(con, \"shakespeare\")\nclass(db_table)\n\n[1] \"tbl_BigQueryConnection\" \"tbl_dbi\"                \"tbl_sql\"               \n[4] \"tbl_lazy\"               \"tbl\"                   \n\n\n실행된 결과를 보면 db_table 객체는 tbl_lazy 클래스로 정의되어 있습니다. 이는 데이터가 실제로 다운로드 되지 않았다는 것을 의미합니다. 이 상태에서 테이블 열 정보를 확인할 수 있습니다.\n이제 샘플 데이터가 준비되었으니 dbplyr 패키지와 dplyr 문법을 사용하여 데이터를 추출해 보겠습니다."
  },
  {
    "objectID": "posts/bigquery-dbplyr/bigquery-dbplyr.html#dbplyr로-bigquery-데이터-추출하기",
    "href": "posts/bigquery-dbplyr/bigquery-dbplyr.html#dbplyr로-bigquery-데이터-추출하기",
    "title": "dbplyr로 bigquery 데이터 추출하기",
    "section": "2. dbplyr로 bigquery 데이터 추출하기",
    "text": "2. dbplyr로 bigquery 데이터 추출하기\nshakespeare 데이터 정보가 저장된 db_table 객체를 사용하여 dbplyr 패키지를 활용하여 데이터를 추출해 보겠습니다.\n\n(1) dplyr 문법으로 테이블 요약하기\n\n# 테이블 열 정보 확인하기\ndb_table %&gt;% glimpse()\n\nRows: ??\nColumns: 4\nDatabase: BigQueryConnection\n$ word        &lt;chr&gt; \"LVII\", \"augurs\", \"dimm'd\", \"plagues\", \"treason\", \"surmise…\n$ word_count  &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ corpus      &lt;chr&gt; \"sonnets\", \"sonnets\", \"sonnets\", \"sonnets\", \"sonnets\", \"so…\n$ corpus_date &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n실행된 결과를 보면 db_table 테이블에는 4개의 열이 있습니다. 아직 전체 데이터 다운로드가 실행되지 않았기 대문에 행 갯수는 ??으로 표시됩니다.\n\n\n(2) dplyr 문법으로 테이블 조작 쿼리 작성하기\ndplyr 패키지를 사용해서 tibble 형태 데이터를 조작하듯 쿼리를 작성할 수 있습니다. 쿼리를 작성하는 것은 실제 데이터를 추출하는 것이 아닙니다.\n\n# shakespeare 테이블에서 작품별로 사용된 단어 수를 계산합니다.\n# 단어 수가 가장 많은 상위 10개 단어를 추출합니다. \nword_count_query &lt;- db_table %&gt;% \n  group_by(word) %&gt;% \n  summarise(count = n()) %&gt;% \n  arrange(desc(count)) %&gt;% \n  head(10)\n\ndbplyr로 작성한 쿼리를 SQL로 확인하고 싶다면 show_query() 함수를 사용합니다.\n\n# SQL 쿼리 확인하기\nshow_query(word_count_query)\n\n&lt;SQL&gt;\nSELECT `word`, count(*) AS `count`\nFROM `shakespeare`\nGROUP BY `word`\nORDER BY `count` DESC\nLIMIT 10\n\n\n이렇게 SQL 문법을 몰라도 dplyr 문법을 사용하여 SQL 쿼리를 작성할 수 있음을 확인할 수 있습니다.\n\n\n(3) 데이터 추출하기\ncollect() 함수를 사용하여 실제 데이터를 추출합니다. collect() 함수를 실행하는 것으로 실제 비용이 발생하게 됩니다. 이 쿼리를 실행하는 경우 10.49MB 데이터를 다운로드 하게 됩니다. 빅쿼리에서는 월 1TB를 무료로 제공하고 있어, 이 글에서 진행하는 실습으로는 추가 비용을 부담하지 않습니다.\n\n# 데이터 추출하기\nword_count &lt;- collect(word_count_query)\n\n\n\n\ncollect() 함수 실행 시 다운로드하는 데이터 크기\n\n\n\n\n(4) 데이터 확인하기\n셰익스피어 테이블에서 가장 많이 사용된 단어 10개를 추출한 결과를 확인합니다.\n\n# 데이터 확인하기\nprint(word_count)\n\n# A tibble: 10 × 2\n   word     count\n   &lt;chr&gt;    &lt;int&gt;\n 1 She         42\n 2 comes       42\n 3 thousand    42\n 4 fall        42\n 5 late        42\n 6 hard        42\n 7 us          42\n 8 himself     42\n 9 There       42\n10 last        42\n\n\n\n\n(5) 데이터베이스 연결 끊기\n데이터 추출이 완료 되었다면 다음 명령을 실행하여 빅쿼리 데이터베이스와 연결을 끊습니다.\n\n# 데이터베이스 연결 끊기\nDBI::dbDisconnect(con)"
  },
  {
    "objectID": "posts/bigquery-dbplyr/bigquery-dbplyr.html#마무리",
    "href": "posts/bigquery-dbplyr/bigquery-dbplyr.html#마무리",
    "title": "dbplyr로 bigquery 데이터 추출하기",
    "section": "3. 마무리",
    "text": "3. 마무리\n이렇게 데이터베이스에 대한 지식이 부족한 R 사용자에게 유용한 패키지 dbplyr를 소개해 드렸습니다. dbplyr 패키지를 사용하여 SQL을 사용하지 않고도 빅쿼리 데이터를 추출할 수 있습니다. 빅쿼리에 저장된 데이터가 너무 많아서 간단하게 데이터 형태를 살펴보고 요약해 보고 싶다면 전체 데이터를 다운로드하지 않아도 되기 때문에 시간과 비용이 크게 절감되니 꼭 활용해 보시기 바랍니다.\n\n\n\n빅쿼리 공개데이터 테이블셋 리스트\ncollect() 함수 실행 시 다운로드하는 데이터 크기"
  },
  {
    "objectID": "posts/bigquery-dbplyr/index.html",
    "href": "posts/bigquery-dbplyr/index.html",
    "title": "dbplyr로 bigquery 데이터 추출하기",
    "section": "",
    "text": "누가, 언제 읽으면 좋을까?\n\n\n\n\ntidyverse 문법에 익숙한 R 사용자가\n\nSQL 구문을 사용하지 않고 빅쿼리 데이터를 추출하고 싶을 때"
  },
  {
    "objectID": "posts/bigquery-dbplyr/index.html#dbplyr-소개",
    "href": "posts/bigquery-dbplyr/index.html#dbplyr-소개",
    "title": "dbplyr로 bigquery 데이터 추출하기",
    "section": "1. dbplyr 소개",
    "text": "1. dbplyr 소개\ndbplyr은 tidyverse 패키지 중 하나로, 데이터베이스에서 데이터를 추출하는 패키지입니다. dbplyr은 R사용자에게 익숙한 dplyr 문법으로 사용하여 *SQL을 사용하지 않고도 데이터베이스에서 데이터를 추출할 수 있게 해 줍니다.\ndbplyr 패키지에서 가장 많이 활용되는 함수는 tbl() 함수로, 데이터베이스에서 테이블을 불러올 때 사용합니다. tbl() 함수를 사용하면 데이터베이스에서 테이블을 불러올 때 사용하는 SQL문을 사용하지 않고도 데이터를 불러올 수 있습니다.\n\n(1) 사용 패키지 설치\n\n# dbplyr을 포함한 tidyverse 패키지를 설치하고 실행합니다. \ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n# 구글빅쿼리 접속을 위한 bigrquery 패키지를 설치하고 실행합니다.\ninstall.packages(\"bigrquery\")\nlibrary(bigrquery)\n\n\n\n(2) 빅쿼리 계정 연결하기\n구글 빅쿼리에 접속하여 이 글에서 사용하는 공개 데이터셋을 활용하려면 빅쿼리 계정이 필요합니다. 빅쿼리 계정 설정 방법은 ‘R에서 구글빅쿼리 데이터 추출하기’를 참고하세요. 계정 설정이 끝났다면 아래 코드를 실행하여 빅쿼리 접속 권한을 설정합니다.\n\n# 계정 연결하기 \nbigrquery::bq_auth()\n\n\n\n(3) 데이터베이스 연결하기\nbigrquery 패키지를 사용하여 구글 빅쿼리에 연결합니다. 연결을 위해서는 dbConnect() 함수를 사용합니다.\n빅쿼리 계정이 준비되었다면, dbConnect() 함수를 사용하여 데이터베이스에 연결합니다.\n\n# 데이터베이스 연결하기 \ncon &lt;- DBI::dbConnect(\n  bigrquery::bigquery(),\n  project = \"bigquery-public-data\",\n  dataset = \"samples\",\n  billing = \"여기에 본인 계정 프로젝트 이름을 넣습니다\"\n)\n\n데이터베이스 연결이 성공하면 con 객체에 데이터베이스 연결 정보가 저장됩니다. 연결이 되었다면, 다음 이미지처럼 RStudio &gt; Connections 탭에서 연결된 데이터베이스가 갖고 있는 테이블 정보를 확인할 수 있습니다.\n\n\n\n빅쿼리 공개데이터 테이블셋 리스트\n\n\n이 글에서는 shakespeare 테이블을 사용하겠습니다.\n\n\n(4) 테이블 불러오기\ntbl() 함수를 사용하여 데이터베이스에서 테이블을 불러올 수 있습니다. shakespeare 테이블을 불러 오겠습니다. 이 때 테이블 데이터가 실제 다운로드 되지 않고, 데이터베이스에 있는 테이블 메타 정보만을 불러옵니다. 이렇게 tbl() 함수를 사용하여 데이터 정보를 보는 것은 데이터 다운로드 비용 발생 없이 테이블 내용을 살펴보기 용이한 빅쿼리 활용 방법입니다.\n\n# 테이블 불러오기    \ndb_table &lt;- tbl(con, \"shakespeare\")\nclass(db_table)\n\n[1] \"tbl_BigQueryConnection\" \"tbl_dbi\"                \"tbl_sql\"               \n[4] \"tbl_lazy\"               \"tbl\"                   \n\n\n실행된 결과를 보면 db_table 객체는 tbl_lazy 클래스로 정의되어 있습니다. 이는 데이터가 실제로 다운로드 되지 않았다는 것을 의미합니다. 이 상태에서 테이블 열 정보를 확인할 수 있습니다.\n이제 샘플 데이터가 준비되었으니 dbplyr 패키지와 dplyr 문법을 사용하여 데이터를 추출해 보겠습니다."
  },
  {
    "objectID": "posts/bigquery-dbplyr/index.html#dbplyr로-bigquery-데이터-추출하기",
    "href": "posts/bigquery-dbplyr/index.html#dbplyr로-bigquery-데이터-추출하기",
    "title": "dbplyr로 bigquery 데이터 추출하기",
    "section": "2. dbplyr로 bigquery 데이터 추출하기",
    "text": "2. dbplyr로 bigquery 데이터 추출하기\nshakespeare 데이터 정보가 저장된 db_table 객체를 사용하여 dbplyr 패키지를 활용하여 데이터를 추출해 보겠습니다.\n\n(1) dplyr 문법으로 테이블 요약하기\n\n# 테이블 열 정보 확인하기\ndb_table %&gt;% glimpse()\n\nRows: ??\nColumns: 4\nDatabase: BigQueryConnection\n$ word        &lt;chr&gt; \"LVII\", \"augurs\", \"dimm'd\", \"plagues\", \"treason\", \"surmise…\n$ word_count  &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ corpus      &lt;chr&gt; \"sonnets\", \"sonnets\", \"sonnets\", \"sonnets\", \"sonnets\", \"so…\n$ corpus_date &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n실행된 결과를 보면 db_table 테이블에는 4개의 열이 있습니다. 아직 전체 데이터 다운로드가 실행되지 않았기 대문에 행 갯수는 ??으로 표시됩니다.\n\n\n(2) dplyr 문법으로 테이블 조작 쿼리 작성하기\ndplyr 패키지를 사용해서 tibble 형태 데이터를 조작하듯 쿼리를 작성할 수 있습니다. 쿼리를 작성하는 것은 실제 데이터를 추출하는 것이 아닙니다.\n\n# shakespeare 테이블에서 작품별로 사용된 단어 수를 계산합니다.\n# 단어 수가 가장 많은 상위 10개 단어를 추출합니다. \nword_count_query &lt;- db_table %&gt;% \n  group_by(word) %&gt;% \n  summarise(count = n()) %&gt;% \n  arrange(desc(count)) %&gt;% \n  head(10)\n\ndbplyr로 작성한 쿼리를 SQL로 확인하고 싶다면 show_query() 함수를 사용합니다.\n\n# SQL 쿼리 확인하기\nshow_query(word_count_query)\n\n&lt;SQL&gt;\nSELECT `word`, count(*) AS `count`\nFROM `shakespeare`\nGROUP BY `word`\nORDER BY `count` DESC\nLIMIT 10\n\n\n이렇게 SQL 문법을 몰라도 dplyr 문법을 사용하여 SQL 쿼리를 작성할 수 있음을 확인할 수 있습니다.\n\n\n(3) 데이터 추출하기\ncollect() 함수를 사용하여 실제 데이터를 추출합니다. collect() 함수를 실행하는 것으로 실제 비용이 발생하게 됩니다. 이 쿼리를 실행하는 경우 10.49MB 데이터를 다운로드 하게 됩니다. 빅쿼리에서는 월 1TB를 무료로 제공하고 있어, 이 글에서 진행하는 실습으로는 추가 비용을 부담하지 않습니다.\n\n# 데이터 추출하기\nword_count &lt;- collect(word_count_query)\n\n\n\n\ncollect() 함수 실행 시 다운로드하는 데이터 크기\n\n\n\n\n(4) 데이터 확인하기\n셰익스피어 테이블에서 가장 많이 사용된 단어 10개를 추출한 결과를 확인합니다.\n\n# 데이터 확인하기\nprint(word_count)\n\n# A tibble: 10 × 2\n   word     count\n   &lt;chr&gt;    &lt;int&gt;\n 1 She         42\n 2 comes       42\n 3 thousand    42\n 4 fall        42\n 5 late        42\n 6 hard        42\n 7 us          42\n 8 himself     42\n 9 There       42\n10 last        42\n\n\n\n\n(5) 데이터베이스 연결 끊기\n데이터 추출이 완료 되었다면 다음 명령을 실행하여 빅쿼리 데이터베이스와 연결을 끊습니다.\n\n# 데이터베이스 연결 끊기\nDBI::dbDisconnect(con)"
  },
  {
    "objectID": "posts/bigquery-dbplyr/index.html#마무리",
    "href": "posts/bigquery-dbplyr/index.html#마무리",
    "title": "dbplyr로 bigquery 데이터 추출하기",
    "section": "3. 마무리",
    "text": "3. 마무리\n이렇게 데이터베이스에 대한 지식이 부족한 R 사용자에게 유용한 패키지 dbplyr를 소개해 드렸습니다. dbplyr 패키지를 사용하여 SQL을 사용하지 않고도 빅쿼리 데이터를 추출할 수 있습니다. 빅쿼리에 저장된 데이터가 너무 많아서 간단하게 데이터 형태를 살펴보고 요약해 보고 싶다면 전체 데이터를 다운로드하지 않아도 되기 때문에 시간과 비용이 크게 절감되니 꼭 활용해 보시기 바랍니다.\n\n\n\n빅쿼리 공개데이터 테이블셋 리스트\ncollect() 함수 실행 시 다운로드하는 데이터 크기"
  },
  {
    "objectID": "posts/bigquery-r/index.html",
    "href": "posts/bigquery-r/index.html",
    "title": "R에서 구글빅쿼리 데이터 추출하기",
    "section": "",
    "text": "언제 읽으면 좋을까?\n\n\n\n\n구글빅쿼리 데이터를 RStudio에서 받아오고 싶을 때\n\n구글빅쿼리와 RStudio 연결 방법을 모를 때\n\nbigrquery 패키지 사용법을 알고 싶을 때"
  },
  {
    "objectID": "posts/bigquery-r/index.html#구글-빅쿼리bigquery란",
    "href": "posts/bigquery-r/index.html#구글-빅쿼리bigquery란",
    "title": "R에서 구글빅쿼리 데이터 추출하기",
    "section": "1. 구글 빅쿼리(BigQuery)란?",
    "text": "1. 구글 빅쿼리(BigQuery)란?\n구글 빅쿼리는 대용량 데이터를 효율적으로 처리하고 분석할 수 있도록 구글에서 제공하는 온라인 데이터베이스 서비스 입니다. 특히 온라인 고객 행동을 모니터링하기 위해 사용하는 GA4(구글애널리틱스4) 데이터를 빅쿼리로 바로 연동하도록 설계되어 있습니다. 이 때문에 GA4 데이터 분석에서는 빅쿼리 사용 점점 늘어나고 있기도 합니다.\n빅쿼리는 많은 양의 데이터를 온라인에서 분석할 수 있도록 쥬피터노트북과 연계되어 있기 때문에 데이터를 다운로드 하는 것 보다는 온라인에서 직접 분석하는 게 더 효율적일 수 있습니다. 그럼에도 불구하고 데이터를 다운로드 받아서 로컬에서 분석해야 하는 경우, bigrquery 패키지를 활용하여 데이터를 다운로드 할 수도 있습니다."
  },
  {
    "objectID": "posts/bigquery-r/index.html#빅쿼리-시작하기",
    "href": "posts/bigquery-r/index.html#빅쿼리-시작하기",
    "title": "R에서 구글빅쿼리 데이터 추출하기",
    "section": "2. 빅쿼리 시작하기",
    "text": "2. 빅쿼리 시작하기\n\n\n\n\n\n\n빅쿼리 설정 먼저\n\n\n\n구글 빅쿼리에 계정과 데이터를 추가한 뒤에 R에서 연결합니다.\n* 계정 만들기\n* 계정에 공개 데이터셋 추가하기\n\n\n\n(1) 빅쿼리 계정 만들기\n빅쿼리 홈페이지를 방문하여 본인의 구글 계정에서 빅쿼리를 사용할 수 있도록 가입합니다. 빅쿼리 시작 시에는 무료이며, 300$의 무료 크레딧이 제공됩니다. 데이터를 불러올 때 용량에 따라 크레딧이 차감되고, 크레딧을 소진하는 경우 추가 비용이 발생할 수 있습니다.\n빅쿼리 계정을 만들면 콘솔(대시보드)가 생성됩니다.\n\n\n(2) 빅쿼리 계정에 공개 데이터셋 추가하기\nbigrquery 설치 후 예제를 수행하기 위해서는 본인의 구글 계정에 테스트용 공개 데이터셋를 먼저 추가해야 합니다. 추가하는 방법은 다음과 같습니다.\n\n빅쿼리 콘솔 &gt; 탐색기(Explorer) &gt; +추가 버튼 클릭\n\n새 창에서 “public data”로 검색 &gt; Public datasets 선택\n\n필터에서 분석, 데이터, 무료 선택 &gt; ‘Google’s diversity annual report data’ 선택: 이 때 무엇을 선택해도 상관없이 나의 데이터 목록에 bigquery-public-data 프로젝트가 추가 됩니다.\n\nbigquery-public-data 프로젝트를 클릭하면 수 많은 데이터 목록이 보이는데, 그 중에 “samples”라는 데이터셋을 테스트 하겠습니다.\n\n\n\n\n(3) 빅쿼리 데이터 구조\n빅쿼리는 프로젝트 &gt; 데이터셋 &gt; 테이블 3단 구조로 설계되어 있습니다. 분석용 데이터는 테이블에 저장되어 있습니다. 우리에게 친숙한 엑셀과 비교하자면, 데이터셋은 파일, 테이블은 시트와 유사한 구조입니다.\n빅쿼리 접속할 경우에 이 3가지 정보를 정확히 입력해야 원하는 데이터를 받을 수 있습니다."
  },
  {
    "objectID": "posts/bigquery-r/index.html#bigrquery-패키지-활용법",
    "href": "posts/bigquery-r/index.html#bigrquery-패키지-활용법",
    "title": "R에서 구글빅쿼리 데이터 추출하기",
    "section": "3. bigrquery 패키지 활용법",
    "text": "3. bigrquery 패키지 활용법\nbigrquery 패키지는 가벼운 API 연동으로 빅쿼리에 저장된 데이터 정보(메타데이터)를 빠르게 받아올 수 있습니다.\n\n(1) 패키지 설치하기\n\ninstall.packages(\"bigrquery\")\nlibrary(bigrquery)\n\n\n\n(2) 계정 인증\n다음 명령을 실행하면 웹 브라우저가 열리면서 구글 계정에 로그인하도록 안내가 됩니다. 계정 연결은 최초 1회만 필요합니다.\n\nbigrquery::bq_auth()\n\n\n\n\n빅쿼리 계정 인증 필요\n\n\n\n\n(3) 공개 데이터셋 정보 확인\n공개 데이터셋 정보는 다음과 같습니다.\n\n프로젝트: “bigquery-public-data”\n\n데이터셋: “samples”\n\n데이터셋 안에 어떤 테이블이 존재하는지 모를 경우, bq_dataset(\"프로젝트명\", \"데이터셋명\") 명령을 실행하여 확인 합니다.\n\nds_sample &lt;- bigrquery::bq_dataset(\"bigquery-public-data\", \"samples\")\nprint(ds_sample)\n\n&lt;bq_dataset&gt; bigquery-public-data.samples\n\n\n데이터에 관한 정보, 즉 메타데이터를 추출하기 때문에 “프로젝트명.데이터셋명”으로 정의된 데이터가 있다고 확인 메세지를 출력합니다.\n데이터셋에 어떤 테이블이 들어 있는지 확인하려면, bq_dataset_tables(\"프로젝트명\", \"데이터셋명\") 명령을 실행 합니다. 여기서는 해당 정보를 ds_samples_tables 변수에 저장합니다.\nds_samples_tables에서 메타데이터 정보를 추출하면 총 7개의 테이블이 있는 것을 알 수 있습니다. 구글 빅쿼리 홈페이지에서 확인했던 7개 테이블과 동일한 정보 입니다.\n테이블 이름은 “프로젝트.데이터셋.테이블”으로 표시됩니다.\n\nds_samples_tables &lt;- bigrquery::bq_dataset_tables(ds_sample) \nprint(ds_samples_tables)\n\n[[1]]\n&lt;bq_table&gt; bigquery-public-data.samples.github_nested\n\n[[2]]\n&lt;bq_table&gt; bigquery-public-data.samples.github_timeline\n\n[[3]]\n&lt;bq_table&gt; bigquery-public-data.samples.gsod\n\n[[4]]\n&lt;bq_table&gt; bigquery-public-data.samples.natality\n\n[[5]]\n&lt;bq_table&gt; bigquery-public-data.samples.shakespeare\n\n[[6]]\n&lt;bq_table&gt; bigquery-public-data.samples.trigrams\n\n[[7]]\n&lt;bq_table&gt; bigquery-public-data.samples.wikipedia\n\n\n\n\n(4) 분석 데이터 선택\n7개 테이블 중 natality 테이블을 선택합니다. bq_table(프로젝트, 데이터셋, 테이블) 명령을 실행하면 해당 테이블에 대한 메타 정보를 출력합니다.\n\nnatality &lt;- bigrquery::bq_table(\"bigquery-public-data\", \"samples\", \"natality\")\nprint(natality)\n\n&lt;bq_table&gt; bigquery-public-data.samples.natality\n\n\n\n\n(5) 빅쿼리 비용 주의사항\n메타데이터는 실제 해당 테이블이 가지고 있는 데이터를 포함하지 않고 단순히 어떤 프로젝트, 데이터셋, 테이블 인지를 정의한 정보 입니다. 데이터를 출력하려면 bq_table_download()를 사용합니다. 이 때 서버에 얼마나 많은 양의 데이터가 있는지 알 수 없기 때문에 모든 데이터를 출력하지 않아야 합니다. 자칫 실수로 전체 데이터를 받을 경우 과도한 비용과 서버 과부하가 발생합니다.\n또한 빅쿼리는 데이터를 “열(column)”을 기준으로 저장합니다. 따라서 열을 조회하는 순간 행(row) 갯수와 관계없이 비용이 부과됩니다.\n빅쿼리는 데이터 저장 비용은 매우 저렴하지만, 데이터를 조회(SELECT)하거나 추출할 때 비용이 발생하기 때문에 sql 쿼리 설계를 잘 해야 운영 비용이 적게 발생합니다.\n따라서 다음과 같이 테이블이 가진 첫 6개 행을 출력하는 것은 비용 절감에 도움이 되지 않습니다.\n첫 6개행 출력하기\n\nnatality_df &lt;- bigrquery::bq_table_download(natality, n_max = 6)\nprint(natality_df)\n\n\n\n\n\n\n\n차라리 출력하는 열 갯수를 줄이는 것이 비용을 많이 절약할 수 있습니다. R에서는 실제 sql 문구를 적용하기 전에는 데이터 양이 얼마나 될 지 미리 알 수가 없습니다. 따라서 빅쿼리 초보 사용자라면 구글 빅쿼리 콘솔에서 실제로 SQL 구문을 수정해 보면서 데이터 양을 비교해 보는 것을 추천합니다.\n\nnatality 테이블 모든 열을 조회하는 경우: 데이터 용량 21.94GB\n\n\n\n\n모든 열 1000개 행 조회 시 용량\n\n\n\nnatality 테이블 중 3개 열에 한정하여 조회하는 경우: 데이터 용량 2.11GB (1/10 정도로 줄었습니다)\n\n\n\n\n3개 열 1000개 행 조회 시 용량\n\n\n\nnatality 테이블 중 3개 열의 행 추출 수를 제한하지 않아도(LIMIT 1000 삭제) 데이터 용량은 2.11 GB로 동일합니다.\n\n\n\n\n3개 열 모든 행 조회 시 용량\n\n\n\n오늘은 R에서 빅쿼리 데이터에 접근해서 데이터를 다운로드하는 기초적인 방법을 알아 봤습니다. 다음 글에서는 필요한 열(column) 정보와 행(row) 정보를 선택할 수 있도록 SQL 코드를 R dplyr 패키지와 유사하게 구현할 수 있는 dbplyr 패키지를 활용해서 효율적인 빅쿼리 데이터 다운로드 방법에 관해 소개하겠습니다.\n\n빅쿼리에 저장된 GA4 데이터를 가장 효율적인 분석 언어 R로 추출해 보세요.\n\n\n\n\n빅쿼리 계정 인증 필요\n모든 열 1000개 행 조회 시 용량\n3개 열 1000개 행 조회 시 용량\n3개 열 모든 행 조회 시 용량"
  },
  {
    "objectID": "posts/quarto-blog/index.html",
    "href": "posts/quarto-blog/index.html",
    "title": "R Quarto로 만드는 블로그",
    "section": "",
    "text": "Artwork by Allison Horst"
  },
  {
    "objectID": "posts/quarto-blog/index.html#배경",
    "href": "posts/quarto-blog/index.html#배경",
    "title": "R Quarto로 만드는 블로그",
    "section": "배경",
    "text": "배경\n제가 논문을 blogdown을 포함하는 bookdown으로 쓰게 된 건, R을 기반으로 한 데이터 분석 결과를 매번 업데이트 하는 과정에서 자잘한 변경을 모두 트래킹 하기 어려웠기 때문입니다. 재현 가능한 연구(reproducible research) 를 위해서라도 R로 논문을 쓰는 게 필요했고, 당시 블로그를 시작할까 도전하면서 며칠을 낑낑 댔던 기억이 나네요.\n이후 등장한 distill은 블로그에 최적화된 간결한 기능을 사용자 친화적인 함수로 제공하여 훨씬 간편해졌어요. distill은 인용, 각주 등이 잘 구현되어 있다는 점, 그리고 css를 잘 몰라도 기본적인 구성은 아주 쉽게 구현할 수 있다는 강점을 갖고 있습니다.\nDistill의 기능을 대부분 포괄하면서 가장 최근에 나온 Quarto Blog 툴은 자바스크립트(JS) 기반 부트스트랩5을 탑재하고 있어 개인화 작업이 손 쉬워 졌습니다."
  },
  {
    "objectID": "posts/quarto-blog/index.html#r로-블로그-만드는-3가지-방법",
    "href": "posts/quarto-blog/index.html#r로-블로그-만드는-3가지-방법",
    "title": "R Quarto로 만드는 블로그",
    "section": "R로 블로그 만드는 3가지 방법",
    "text": "R로 블로그 만드는 3가지 방법\n\nblogdown (2017 ~ ): R로 작성하는 html 기초 문법 제공\n\nbookdown 패키지의 서브 버전으로 기본 문법을 이해하면 다른 패키지나 시스템 이해도가 크게 높아집니다.\n\n온라인 ebook은 무료로 제공 되고 있습니다.\n\n패키지 저자 Yihui Xie의 공식 가이드북을 추천합니다.\n\ndistill (2018 ~ ): 블로그에 최적화된 레이아웃 제공\n\n과학 블로그, 기술 블로그에 최적화된 웹출판 도구로 패발된 패키지 입니다.\n\n수학식, 인용, 각주 등을 손쉽게 사용할 수 있도록 편의성을 제공합니다.\n\n각종 편의 기능을 제공하는 함수로 블로그 포스팅을 쉽고 빠르게 할 수 있어요.\n\nquarto 블로그 시스템에 distill을 차용하고 있기 때문에 레퍼런스로 활용할 만 합니다.\n\n공식 홈페이지는 여기 참고하세요.\n\nquarto (2022 ~ ): 패키지가 아닌 문서 작성 도구 distill 기능을 대부분 계승합니다.\n\nQuarto는 Posit에서 공식 개발, 확장 중인 시스템으로 빠르게 기능이 확장 되고 있습니다.\nR 생태계를 파이썬과 연결하려는 시스템 입니다.\nRStudio 외에 쥬피터노트북, VS Code에서도 사용할 수 있어요."
  },
  {
    "objectID": "posts/quarto-blog/index.html#quarto-장점",
    "href": "posts/quarto-blog/index.html#quarto-장점",
    "title": "R Quarto로 만드는 블로그",
    "section": "Quarto 장점",
    "text": "Quarto 장점\n\nR 패키지가 아닌 문서 작성 시스템 입니다.\n\nR 이외 파이썬 언어로도 작성 가능합니다.\n\n블로그, 홈페이지, MS워드, PDF, ePub 등 다양한 문서 작성을 지원합니다.\nQuarto -&gt; Github -&gt; 제3자 퍼블리싱 연계가 쉽습니다."
  },
  {
    "objectID": "posts/quarto-blog/index.html#quarto-단점",
    "href": "posts/quarto-blog/index.html#quarto-단점",
    "title": "R Quarto로 만드는 블로그",
    "section": "Quarto 단점",
    "text": "Quarto 단점\n\n개인화 하려면 배워야 할 게 많습니다.\n\nR마크다운, yaml, html, css, JS는 기본적으로 이해할 필요가 있어요.\ngit에 대한 기본 이해도 필요해요.\nNetlify 같은 호스팅 서비스도 필요해요.\n\n패키지가 아니라서 클릭 한 번으로 블로그 포스팅 템플릿이 자동 생성되지 않습니다.\n\n블로그 포스팅 마다 폴더를 만들고, 그 안에 Rmd(R마크다운) 파일을 개별 생성해야 합니다."
  },
  {
    "objectID": "posts/quarto-blog/index.html#어떻게-시작하나요",
    "href": "posts/quarto-blog/index.html#어떻게-시작하나요",
    "title": "R Quarto로 만드는 블로그",
    "section": "어떻게 시작하나요?",
    "text": "어떻게 시작하나요?\n\nQuarto 설치\nPosit 홈페이지에서 사용하는 OS 시스템에 맞는 버전을 다운로드 후 설치 합니다. 2024-02-15 1.4.550 버전이 출시 되었습니다.\n\n\nQuarto Blog 프로젝트 만들기\n가장 쉬운 방법은 RStudio에서 신규 프로젝트를 생성할 때, Quarto Blog를 선택하는 겁니다. 프로젝트에서 자동으로 기본 뼈대 구성에 필요한 폴더들과 파일을 만들어 줍니다. 일단은 개인화는 나중에 생각하고, 해당 템플릿을 활용해서 index.Rmd를 나의 블로그 포스팅으로 수정하기만 해도 블로그를 시작하는 거죠.\n여기까지 얼마나 걸릴까요? 블로그 포스팅 소재만 준비되어 있다면 하루도 안 걸립니다.\n\n\nGithub 연동하기\ngit에 대해 잘 모르거나 github를 써 보지 않았다면 처음에 조금 헤맬 수 있어요. 관련된 포스팅은 다음 기회에 자세히 하기로 하구요, 초보를 위한 usethis 패키지를 활용할께요.\n\n(1) 깃헙 계정 만들기\nGitHub 계정이 없다면 이번 기회에 만듭니다.\n\n\n(2) usethis 패키지 설치\nusethis 패키지를 설치 하고 불러 옵니다.\n\n#install.packages(\"usethis\")\nlibrary(usethis) \n\n\n\n(3) 깃헙 계정과 RStudio 연결\nHappy Git and GibHub for the useR을 참조하시면 왠만한 건 다 해결 될 거에요.\n우리가 참고할 부분은 17 Existing project, Github last입니다.\n\nusethis::use_git()\n\n\n\n(4) 깃 패널 확인\n위 명령을 실행하면 RStudio 우측 상단 Environment가 있는 패널에 ’Git’이라는 패널이 새로 생길 거에요.\n\n\n\nGit 패널이 생기면 성공\n\n\n\n\n(5) 깃헙 연결하는 개인화토큰(PAT) 만들기\n다음 명령을 실행하면 깃헙 내 계정으로 로그인하는 창이 브라우저에 뜹니다. 브라우저에서 로그인 하면 PAT 만드는 페이지로 바로 접속 됩니다.\n\ncreate_github_token()\n\nNote 빈 칸에 적당한 이름을 만들어서 저장합니다. 다음 페이지에서 창을 절대 닫지 마시고 생성된 PAT를 복사하세요.\n\n\n\nPAT만드는 깃헙페이지로 연결됩니다\n\n\n다음 코드를 실행해서 시스템에 생성한 PAT를 저장합니다. 저는 이미 PAT가 저장되어 있기 때문에, 다음과 같이 기존 코드를 바꾸냐는 옵션이 있는 점 참고해 주세요.\n\ngitcreds::gitcreds_set()\n\n\n\n\n콘솔에서 옵션을 선택해서 저장\n\n\n\n\n(6) 깃헙에 블로그 레포지토리 생성\n다음 코드를 실행해서 깃헙에 프로젝트 이름으로 새로운 레포지토리를 생성합니다.\n\nuse_github() \n\n깃헙 홈페이지에서 새로 만들어진 레포지토리를 확인 합니다. 아직은 비어 있을 거에요.\n\n\n(7) 첫 커밋을 실행\n(4)번에서 본 Git 패널로 다시 갑니다. 아직 git에 연동되지 않은 파일 리스트가 있을 겁니다. 다음과 같이 실행하세요.\n\nDiff 아이콘을 열고, 모두 선택해서(staged)\n\n커밋 메세지를 적어요\n\n나중에 변경 이력 관리하기 위해서 어떤 내용 변경인지 요약한다고 생각하면 됩니다.\n\n\ncommit 버튼 클릭\n\npush 버튼 클릭\n\n간혹 push 버튼이 활성화 되지 않을 경우가 있어요. 그럴 때는 Terminal로 이동해서 직접 git 연동을 시켜 줍니다.\n\ngit push origin main\n\n\n\n(8) 깃헙 홈페이지 확인\n제대로 업로드가 되었는지 깃헙 홈페이지에 레포지토리를 확인하세요."
  },
  {
    "objectID": "posts/quarto-blog/index.html#사용-소감",
    "href": "posts/quarto-blog/index.html#사용-소감",
    "title": "R Quarto로 만드는 블로그",
    "section": "사용 소감",
    "text": "사용 소감\n글이 너무 길어져서… 웹에 배포하는 Netlify 연동은 다음 포스팅에서 다룰께요.\nNetlify 연동방법 글 바로가기\nQuarto 설치 후 첫 블로그 포스팅 까지 딱 하루가 걸렸어요. 물론 저는 R 사용에 능숙하고 기존에 blogdown, distill 썼던 경험이 있어서 수월 했을 수도 있다고 생각합니다. 그럼에도 Quarto가 워낙 사용하기 쉽기 때문에 개발자가 아니어도 누구나 R을 활용한 블로그를 개설할 수 있습니다. Wordpress 블로그 개설이 너무 어려웠다면, Quarto를 찬찬히 따라해 보는 것 추천합니다. 여러분도 할 수 있어요.\n\n\n\nArtwork by Allison Horst\nGit 패널이 생기면 성공\nPAT만드는 깃헙페이지로 연결됩니다\n콘솔에서 옵션을 선택해서 저장"
  },
  {
    "objectID": "posts/quarto-blog-seo-setting/index.html",
    "href": "posts/quarto-blog-seo-setting/index.html",
    "title": "Quarto 블로그 SEO 최적화 3가지 꿀팁",
    "section": "",
    "text": "구글 검색 시스템에서 내가 작성한 블로그 글이 누락되지 않도록 하려면 구글 서치 콘솔에 홈페이지를 등록해야 합니다.\n구글 서치 콘솔에 접속 합니다.\n속성 추가 버튼을 눌러서 내 홈페이지를 등록 합니다. 도메인을 구매하여 DNS 정보가 있다면 도메인(신규) 옵션을 선택합니다. 이 블로그 처럼 Netlify, rbind.io 등 직접 구매하지 않은 도메인으로 DNS 관리 정보가 없는 경우는 URL 접두어옵션에서 홈페이지 주소를 입력 합니다.\n\n\n\n구글 서치콘솔에서 홈페이지 등록하기"
  },
  {
    "objectID": "posts/quarto-blog-seo-setting/index.html#서치콘솔에-홈페이지-등록",
    "href": "posts/quarto-blog-seo-setting/index.html#서치콘솔에-홈페이지-등록",
    "title": "Quarto 블로그 SEO 최적화 3가지 꿀팁",
    "section": "",
    "text": "구글 검색 시스템에서 내가 작성한 블로그 글이 누락되지 않도록 하려면 구글 서치 콘솔에 홈페이지를 등록해야 합니다.\n구글 서치 콘솔에 접속 합니다.\n속성 추가 버튼을 눌러서 내 홈페이지를 등록 합니다. 도메인을 구매하여 DNS 정보가 있다면 도메인(신규) 옵션을 선택합니다. 이 블로그 처럼 Netlify, rbind.io 등 직접 구매하지 않은 도메인으로 DNS 관리 정보가 없는 경우는 URL 접두어옵션에서 홈페이지 주소를 입력 합니다.\n\n\n\n구글 서치콘솔에서 홈페이지 등록하기"
  },
  {
    "objectID": "posts/quarto-blog-seo-setting/index.html#사이트맵-제출",
    "href": "posts/quarto-blog-seo-setting/index.html#사이트맵-제출",
    "title": "Quarto 블로그 SEO 최적화 3가지 꿀팁",
    "section": "2. 사이트맵 제출",
    "text": "2. 사이트맵 제출\n\n(1) 사이트맵 생성하기\nQuarto 블로그는 자동으로 사이트맵을 생성해주지 않기 때문에, yaml에 사이트맵을 추가하는 옵션을 넣어 주어야 합니다.\n수정해야 하는 파일은 _quarto.yml입니다.\n이 블로그 사이트를 예시로 설명 드리겠습니다. 아래에는 이 블로그를 만들기 위한 _quarto.yml 파일 중 일부를 발췌해서 보여 드리고 있습니다.\n---\nproject:\n  type: website\n\nwebsite:\n  title: \"Mindful Analytics\"\n---\n_quarto.yml 파일에 다음과 같이 2줄을 추가해서 sitemap을 만들 수 있습니다.\n\nwebsite 옵션 아래 site-url: “내 웹사이트 주소”를 추가합니다.\nsite-path: “/”는 사이트맵이 생성될 경로를 의미합니다.\n\n아래 옵션으로 추가되는 파일은 _site 폴더 안에 sitemap.xml 파일입니다. 해당 xml 파일은 site-path에서 “/”다음에 넣으라고 지정했기 때문에 홈페이지주소/사이트맵 형태로 추가됩니다. 이 블로그의 사이트맵은 다음 위치에 있습니다. https://seheeopark.rbind.io/sitemap.xml\n---\nproject:\n  type: website\n\nwebsite:\n  title: \"Mindful Analytics\"\n1  site-url: \"https://seheeopark.rbind.io\"\n2  site-path: \"/\"\n---\n\n1\n\n사이트 주소를 입력합니다.\n\n2\n\n사이트맵이 생성될 경로를 지정합니다.\n\n\n사이트맵을 만드는 yaml을 저장한 다음 블로그를 새로 render 해야 sitemap.xml 파일이 생성됩니다. _site 폴더 안에 sitemap.xml 파일을 확인해서 최신 홈페이지 구성으로 사이트맵이 잘 생성되었는지 확인할 수 있습니다.\n\n\n(2) 사이트맵 제출하기\n내 홈페이지가 등록된 구글 서치콘솔의 색인생성 &gt; Sitemaps 메뉴에서 사이트맵을 추가합니다. 사이트맵이 위치한 경로는 Quarto yaml에서 지정한 경로와 동일합니다. 사이트맵 등록 방법은 다음 동영상을 참고해 주세요."
  },
  {
    "objectID": "posts/quarto-blog-seo-setting/index.html#메타설명-추가",
    "href": "posts/quarto-blog-seo-setting/index.html#메타설명-추가",
    "title": "Quarto 블로그 SEO 최적화 3가지 꿀팁",
    "section": "3. 메타설명 추가",
    "text": "3. 메타설명 추가\nQuarto 블로그는 metadata를 추가하여 블로그 글의 검색 엔진 최적화를 할 수 있습니다. 가장 손쉽게 구글 서치 엔진에 정보를 제공하는 방법은 각 블로그 포스팅 마다 description을 추가하는 것 입니다.\ndescription은 블로그 글의 요약된 정보를 의미합니다. 구글 검색 시스템은 html 메타정보에서 description을 우선 읽어 들여, 사용자에게 찾는 정보에 근접한 페이지를 노출합니다. 따라서 이 description을 블로그 글을 정확히 요약하여 전달하도록 작성함으로써 검색 상위 노출 효과를 노릴 수 있습니다.\n구글에서는 우수한 메타 설명을 만드는 권장사항을 다음과 같이 제시하고 있습니다.\n\n각 페이지마다 고유한 설명을 작성합니다.\n페이지의 주요 내용을 요약합니다.\n\n\n\n\n구글 메타설명 권장사항 예시\n\n\n더 자세한 구글 권장사항은 여기에서 확인할 수 있습니다.\n이 블로그 글의 description은 다음과 같이 추가되어 있습니다.\n---\ntitle: \"Quarto 블로그 SEO 최적화\"\ndescription: \"Quarto로 만드는 블로그 구글 검색 상위 노출을 위한 SEO 최적화를 위해 서치콘솔 등록, 사이트맵 제출, 메타설명 추가 방법을 다룹니다.\"\n---\n\n여러분이 열심히 작성한 Quarto 블로그가 구글 검색에 누락되지 않도록, 오늘 소개해 드린 3가지 SEO 세팅은 꼭 신경써서 등록하시길 바랍니다.\n\n\n\n구글 서치콘솔에서 홈페이지 등록하기\n구글 메타설명 권장사항 예시"
  },
  {
    "objectID": "posts/netlify-deployment/index.html",
    "href": "posts/netlify-deployment/index.html",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "",
    "text": "Artwork by Allison Horst"
  },
  {
    "objectID": "posts/netlify-deployment/index.html#먼저-참고하면-좋은-글",
    "href": "posts/netlify-deployment/index.html#먼저-참고하면-좋은-글",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "먼저 참고하면 좋은 글",
    "text": "먼저 참고하면 좋은 글\nR Quarto로 블로그 만들기\n\nQuarto로 하루 만에 블로그 만드는 방법이 궁금하다면?\nGitHub와 Quarto 블로그 프로젝트를 연결하려면?"
  },
  {
    "objectID": "posts/netlify-deployment/index.html#netlify가-무엇이죠",
    "href": "posts/netlify-deployment/index.html#netlify가-무엇이죠",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "Netlify가 무엇이죠?",
    "text": "Netlify가 무엇이죠?\n정적 웹사이트를 호스팅하고 관리할 수 있는 무료 플랫폼 입니다. R 커뮤니티 뿐만 아니라 기술 블로그를 운영하는 다양한 개발자 커뮤니티에서 인기있는 서비스 입니다.1 Quarto 블로그는 기본적으로 미리 knit을 통해 완성한 html을 서버로 전송하는 방식을 채택합니다. 따라서 웹 호스팅이 간편하고 빠르며 보안성이 높습니다."
  },
  {
    "objectID": "posts/netlify-deployment/index.html#netlify-쉬운가요",
    "href": "posts/netlify-deployment/index.html#netlify-쉬운가요",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "Netlify 쉬운가요?",
    "text": "Netlify 쉬운가요?\n네!\n다음과 같은 설정 1번만 해 두면, 블로그에 새 글을 추가하거나 변경하는 내용이 자동으로 배포됩니다. 이를 지속적 배포(continuous deployment) 라고 합니다. 이런 기술적 용어나 원리는 몰라도 됩니다. Netlify 서비스가 모든 것을 관리해 주니까요.\n여러분이 할 일은 Quarto로 만든 블로그 작성 프로젝트를 깃헙에 연동한 뒤, Netlify에 해당 깃헙을 연결하는 설정 1번만 하는 것이에요.\n해외 서비스라서 모든 기능이 영어로만 제공된다는 것이 조금 불편할 수 있지만, 구글 번역기 등을 활용해서 충분히"
  },
  {
    "objectID": "posts/netlify-deployment/index.html#깃헙---netlify-연결하기",
    "href": "posts/netlify-deployment/index.html#깃헙---netlify-연결하기",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "깃헙 - Netlify 연결하기",
    "text": "깃헙 - Netlify 연결하기\nQuarto 블로그 프로젝트를 깃헙에 연결하는 방법은 이 블로그 포스팅 도입부에 소개한 R Quarto로 블로그 만들기 글을 참고해 주세요. 여기서는 깃헙 연동에 성공한 이후 Netlify 연결 방법에 관해 소개합니다.\n\n(1) Netlify 계정 만들기\nNetlify 바로가기\n처음 시작하는 계정은 무료 입니다. 추후 블로그 방문자 트래픽이 커지면 비용이 발생할 수 있지만, 대부분의 개인 블로그 정도는 무료로 운영 가능합니다. 무료 계정 허용 용량 이상 트래픽은 로그인 후 제공하는 대시보드 형태 화면에서 확인 가능 합니다.\n신규 계정 만들 때는 깃헙 계정을 연동하는 방식을 추천 합니다. 어차피 우리가 배포하려는 서비스가 깃헙에 등록되어 있기 때문에 다른 이메일 주소로 가입하더라도 깃헙 계정과 연동을 해야 하긴 합니다.\n\n\n(2) 깃헙 레포지토리 불러오기\n\n로그인 후 보이는 화면에서 Add new site 클릭\nImport an existing project 선택\nDeploy with GitHub 선택\n깃헙 계정과 연동 허용\nNetlify에서 배포할 레포지토리를 선택\n\n\n\n\n등록할 깃헙 레포지토리 설정하는 방법\n\n\n\n\n(3) 사이트 이름 지정\n\n기본적으로 xxxx.netlify.app 이라는 홈페이지 주소가 자동 부여됩니다.\nSite name에 내가 원하는 서브 도메인 이름을 영어로 작성하여 사용 가능 여부를 확인 합니다.\n\n이 단계에서 놓쳐도 설정에서 변경할 수 있어요.\n\n\n\n\n\n사이트명 설정하기\n\n\n\n\n(4) (가장 중요) 배포 폴더 지정\n\nBuild settings &gt; Publish directory 에서 _site 라고 입력합니다.\n\n이 옵션은 Quarto 블로그 프로젝트를 생성했다면 공통 적용 입니다.\n\n다른 것은 수정하거나 추가하지 마세요.\nDeploy XXX (배포할 레포지토리 이름) 버튼 클릭하세요\n\n\n\n\n_site 라고 입력하기\n\n\n여기까지 5분 정도 걸리셨나요? 모든 설정이 끝났어요. 진짜로요."
  },
  {
    "objectID": "posts/netlify-deployment/index.html#이제-블로그-쓰기만-하세요",
    "href": "posts/netlify-deployment/index.html#이제-블로그-쓰기만-하세요",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "이제 블로그 쓰기만 하세요",
    "text": "이제 블로그 쓰기만 하세요\n지금 여러분이 보고 있는 Mindful Analytics 블로그도 바로 Quarto-GitHub-Netlify 조합으로 만들고 배포 하였습니다. 이 연동 설정은 1회만 하면 됩니다. 앞으로는 Quarto로 추가 포스팅 작성 후 GitHub로 커밋 & 푸쉬만 하면 Netlify가 해당 변경 내용을 실시간으로 받아서 웹사이트를 상시 업데이트 해 줍니다. 변경에 대한 배포에 대해 고민할 필요가 없는 것이 Netlify를 쓰는 가장 큰 장점 이에요.\n\n(보너스) 연동 후 새로운 글 배포하는 방법\n\nposts 폴더 안에 새로운 블로그 글을 작성할 폴더를 만듭니다.\n\n작성할 포스트 제목을 나타내는 키워드를 영어로 골라서 폴더명을 쓰세요.\n예를 들어, 제가 작성 중인 이 포스트는 netlify-deployment 폴더 안에 있습니다.\n이 폴더 이름이 블로그 글 주소에 들어가게 됩니다.\n\n새로 만든 폴더 안에 .qmd 파일을 생성하고 블로그 템플릿을 참고하여 새 글을 작성합니다.\n\n추가할 그림이나 데이터는 이 폴더 안에 함께 담아 주면 별도 경로 지정할 필요가 없어요.\n\n글 작성 후 웹 등록하려면 다음 2가지를 꼭 기억하세요.\n\n블로그 .qmd의 yaml 헤더에 draft: false 인지 꼭 확인하세요 (삭제하면 더 좋아요)\n다 작성한 뒤 반드시 Render를 해서 html 파일을 생성합니다. 변경 사항 저장 시 자동 Render 되도록 Render on Save 옵션을 활성화하면 편리합니다.\n_site 폴더 안에 내가 만든 포스팅 폴더가 추가 되었는지 확인하세요\n\n깃헙에 변경된 내용을 커밋 & 푸쉬하는 것 잊지 마세요.\n\n\n여러분도 R로 쓰는 블로그, Quarto-GitHub-Netlify 조합으로 쉽고 빠르게 만들어 나가시길 바랍니다.\n\n\n\nArtwork by Allison Horst\n등록할 깃헙 레포지토리 설정하는 방법\n사이트명 설정하기\n_site 라고 입력하기"
  },
  {
    "objectID": "posts/netlify-deployment/index.html#footnotes",
    "href": "posts/netlify-deployment/index.html#footnotes",
    "title": "R Quarto로 만든 블로그 배포(feat. Netlify)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n정적 웹사이트란 미리 웹 페이지 내용이 생성되어 서버에서 사용자 요청에 따라 생성되거나 처리되는 컨텐츠가 없는 사이트 입니다.↩︎"
  },
  {
    "objectID": "posts/copilot-in-rstudio/index.html#copilot-소개",
    "href": "posts/copilot-in-rstudio/index.html#copilot-소개",
    "title": "RStudio에서 Copilot 쓰기",
    "section": "1. Copilot 소개",
    "text": "1. Copilot 소개\n프로그래머를 위한 AI 짝궁으로 깃헙에서 출시한 - OpenAI와 공동 개발한 - 코파일럿. 쓰지 않은 사람은 있어도 한 번 쓰고 안 쓰는 사람은 없을 것 같아요. 그만큼 코파일럿을 사용할 때 코드 작성하는 시간이 크게 단축되고 있습니다. 깃헙에 저장된 수많은 프로그래밍 언어를 기반으로 훈련된 LLM AI 모델로 수시로 바뀌는 최신 패키지 내용도 잘 숙지하고 있어요. 개인적인 소감으로는 챗GPT 보다 더 간결하면서 명확한 코드, 특히 깔끔한 주석을 제안해 주기 때문에 “코파일럿이 한 수 위다”라고 생각합니다.\n깃헙 공홈에서도 RStudio에서 코파일럿이 활용 가능하다는 점을 홍보하지 않고 있기 때문에 의외로 RStudio 사용자들이 코파일럿을 사용하지 않는 경우가 있는 것 같습니다. 이 글에서는 RStudio에서 코파일럿을 사용하는 방법을 소개하고, 코파일럿을 사용하면서 느낀 점을 공유하겠습니다.\n\n(1) 깃헙 계정 준비\n코파일럿은 유료이며 깃헙 계정 연동이 필요합니다.\n\n깃헙 계정이 개인 계정이라면 개인용 코파일럿을 사용합니다.\n회사(단체) 깃헙을 사용한다면 회사에서 구매한 코파일럿을 함께 활용할 수 있습니다.\n\n이 글에서는 개인용 코파일럿 사용법을 중심으로 설명합니다.\n\n\n(2) 코파일럿 비용\n2024년 3월 현재, 개인용 코파일럿 비용은 월 $10 USD 입니다. 월 구독 형태로 언제든 해지 가능하구요. 연 구독을 이용하면 $100 USD로 약 2달 정도 금액을 할인해 줍니다. 깃헙 계정당 1회에 한해 첫 30일은 무료로 활용할 수 있으니 조금 써 보다가 생각보다 활용도가 높지 않다면 30일 이내에 해지하는 것도 가능합니다.\n여러 개 IDE를 사용해도 코파일럿 비용은 월 1건만 청구됩니다. 저는 R은 RStudio, 파이썬은 VS Code를 이용하고 있어 2군데 다 연동을 해 놓았습니다. RStudio에서는 코파일럿 연동이 조금 늦게 되어서 (2023.11월 정식 출시) 코파일럿 연동된 VS Code 쓰다가 RStudio를 쓰면 조금 느려진 느낌이었는데, 이제 RStudio에서도 코파일럿을 맘껏 쓸 수 있어 너무 좋습니다."
  },
  {
    "objectID": "posts/copilot-in-rstudio/index.html#rstudio에-copilot-연동하기",
    "href": "posts/copilot-in-rstudio/index.html#rstudio에-copilot-연동하기",
    "title": "RStudio에서 Copilot 쓰기",
    "section": "2. RStudio에 Copilot 연동하기",
    "text": "2. RStudio에 Copilot 연동하기\nRStudio 버전 2023.09.0 이후 버전부터 코파일럿 연동을 제공하고 있으니 최신 버전을 Posit 홈페이지를 통해 설치하시는 것을 추천합니다.\n\n(1) 깃헙에서 코파일럿 유료 구독 하기\n\n깃헙 로그인 후 우측 상단 내 계정 아이콘을 눌러 “Setting” 메뉴에 접속합니다.\n3번째 ‘Code, planning, and automation’ 메뉴에서 Copilot을 선택합니다.\n결제 정보 입력 후 구독을 시작합니다.\n\n\n\n(2) 코파일럿 연동하기\nRStudio가 제공하는 메뉴를 활용해서 1분 이내로 쉽게 연동할 수 있습니다. 하단 동영상에 자세한 방법을 소개했으니 참고해 주세요.\n\nRStudio 메뉴에 Tools &gt; Global Options &gt; Copilot을 선택합니다.\n첫번째 옵션에서 “Enable GitHub Copilot”을 체크박스를 선택합니다.\n팝업 창에서 링크와 코드를 안내합니다. 팝업 창 닫지 말고 코드를 메모하세요.\n팝업 창 내 링크를 열어서 코파일럿을 구독하는 내 깃헙 계정으로 로그인 합니다.\n로그인 후 나오는 코드 입력 창에서 안내 받은 코드 8자리를 입력하세요.\n\n\n\n(3) 코파일럿 사용 옵션\nRStudio에서 Tools &gt; Global Options &gt; Copilot 메뉴로 접속하면, 2가지 옵션이 더 있습니다.\n\nCopilot Indexing: 작업하는 프로젝트 폴더를 코파일럿이 접근하여 해당 코드를 활용하도록 허용할지 결정합니다. 체크박스를 선택 시 접근 허용하게 됩니다.\nCopilot Completion: 마지막 입력 후 시간이 얼마나 지났을 때 코파일럿이 코드를 제안할 지 시간을 설정합니다. 기본값은 300ms 입니다."
  },
  {
    "objectID": "posts/copilot-in-rstudio/index.html#copilot-활용-시연",
    "href": "posts/copilot-in-rstudio/index.html#copilot-활용-시연",
    "title": "RStudio에서 Copilot 쓰기",
    "section": "3. Copilot 활용 시연",
    "text": "3. Copilot 활용 시연\n코파일럿을 활용한 코드 작성 시연을 통해 어떻게 코드를 제안하는지 확인해 보겠습니다.\n간단히 R에 내장된 mtcar 데이터를 활용하여 histogram을 그려보도록 코파일럿을 활용하겠습니다.\n\n먼저 코파일럿에게 내가 무엇을 할 지 간단히 주석으로 설명합니다.\n입력을 멈추고 기다리면 코파일럿이 코드를 제안하기 시작합니다. 제안하는 코드는 연한 회색으로 표시됩니다.\n제안한 코드를 받아들여 사용하려면 Tab 키를 누르면 됩니다.\n\n다음 코드는 100% 코파일럿이 제안한 코드 입니다. 코파일럿이 생성하는 코드는 매번 달라지기 때문에 여러분이 쓰실 때와 다를 수 있습니다.\n\n기본 버전\n\n\n# mtcars histogram\nhist(mtcars$mpg)\n\n\n\n\n\n\n\n\n\nggplot2 버전\n\n\n# mtcars histogram with dplyr and ggplot2 \nlibrary(dplyr)\nlibrary(ggplot2)\n\nmtcars %&gt;% \n  ggplot(aes(x = mpg)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\nggplot2 고급 버전\n\n\n# mtcars histogram with ggplot2, white background, blue fill color \n# better bins, better title\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nmtcars %&gt;% \n  ggplot(aes(x = mpg)) +\n  geom_histogram(fill = \"blue\", bins = 20) +\n  theme_minimal() +\n  labs(title = \"Histogram of mtcars mpg\")\n\n\n\n\n\n\n\n\n제가 한 것이라고는 주석을 잘 달아서 방향을 알려준 뒤, tab과 enter 키를 누른 것 뿐 입니다.\n\n설치 및 활용 동영상\n코파일럿 설치부터 샘플 코드 작성까지 아래 동영상을 통해 확인해 보세요."
  },
  {
    "objectID": "posts/copilot-in-rstudio/index.html#copilot-활용-팁",
    "href": "posts/copilot-in-rstudio/index.html#copilot-활용-팁",
    "title": "RStudio에서 Copilot 쓰기",
    "section": "4. Copilot 활용 팁",
    "text": "4. Copilot 활용 팁\n코파일럿을 사용하면서 몇 가지 팁을 공유하겠습니다.\n\n(1) 명확한 주석 달기\n코파일럿에게 코드 추천을 잘 받으려면 명확하게 주석을 달아주는 것이 중요합니다. 위 예시에서 보았듯이 dplyr과 ggplot2를 사용하여 히스토그램을 그리겠다고 하니, 해당 패키지를 활용하는 코드로 제안해 줍니다.\n\n\n(2) 제안 코드 확인하기\n코파일럿이 제안하는 코드가 꼭 내가 작성하려던 내용이 아닐 수 있습니다. 따라서 코드를 무작성(무지성으로) 받지 않고, 한줄 한줄 꼼꼼하게 읽으면서 내가 원하는 코드인지 확인해야 합니다.\n프로그래밍 초보 시절에는 특히 코드가 무엇을 의미하는지 100% 이해하지 못하고 여기저기서 ctrl + c & v 하기 바쁜데요. 이 때 해당 코드를 한줄 한줄 실행하면서 어떤 결과가 나오는지 직접 확인하는 것이 좋습니다.\n만약 결과값이 내가 예상한 방향이 아니라면 코파일럿 제안 내용을 삭제하고 좀 더 명확한 주석을 적어 코파일럿이 다시 제안하도록 합니다.\n\n\n(3) 제안 코드 수정하기\n코파일럿이 제안한 코드가 아주 방향이 다르지 않을 때는, 해당 코드를 직접 수정합니다. 가령 위 예시에서 히스토그램을 ggplot2 패키지로 그렸을 때 막대 너비를 수정하고 싶었는데 코파일럿이 제대로 제안하지 못 했어요. bins 옵션을 직접 추가해서 해결할 수 있었습니다."
  },
  {
    "objectID": "posts/copilot-in-rstudio/index.html#copilot-활용-후기",
    "href": "posts/copilot-in-rstudio/index.html#copilot-활용-후기",
    "title": "RStudio에서 Copilot 쓰기",
    "section": "5. Copilot 활용 후기",
    "text": "5. Copilot 활용 후기\n\n코파일럿을 사용하면서 코드 작성 시간이 확실히 단축되었습니다.\n\n특히 코파일럿은 코드만 제안하는 것에서 더 나아가 명확한 주석도 추가해 주기 때문에, 코드를 읽고 이해하기 쉽게 작성할 수 있었습니다. 다른 팀원들과 코드를 공유해야 한다면 코파일럿 사용 시 편안하게 코드를 작성할 수 있습니다.\n\n코파일럿에 제안하는 주석이나 코드가 내가 읽기에 명확하지 않을 때도 있어요.\n\n코파일럿이 대충 써 준 내용을 정교하게 다듬으면서 나의 문서 작성 실력도 한층 업그레이드 되는 것 같습니다.\n\n시작을 망설이거나 빈 화면에 부담을 느끼는 시간이 크게 단축 됩니다.\n\n코파일럿과 함께 코드 작성을 바로 시작하세요. 코드를 하나도 몰라도 시작할 수 이어요.\n\n코파일럿을 사용 시 비용이 꾸준하게 발생하지만, 프로그래밍에 있어서는 어떤 AI 지원 도구보다 만족도가 높습니다.\n\n[Disclaimer] 제 후기가 너무 칭찬 일색이라 의심하실 수도 있을 것 같은데, 이 글은 깃헙에서 어떠한 지원도 받지 않은 활용기 입니다. 여러분도 코파일럿과 함께 빠르게 R 숙련도를 높이면 좋겠다는 바람으로 작성하였으니 오해 없으시길 바랍니다."
  },
  {
    "objectID": "posts/which-data-warehouse-to-choose/index.html#데이터-웨어하우스-란",
    "href": "posts/which-data-warehouse-to-choose/index.html#데이터-웨어하우스-란",
    "title": "클라우드 데이터 웨어하우스 어떤 기준으로 고를까?",
    "section": "1. 데이터 웨어하우스 란?",
    "text": "1. 데이터 웨어하우스 란?\n데이터 웨어하우스는 의사결정 지원 시스템으로 데이터를 저장, 처리, 분석 하도록 설계된 클라우드 기반 데이터베이스 시스템 입니다. 데이터 웨어하우스는 비즈니스 인텔리전스(BI), 데이터 마이닝, 예측 분석 등 다양한 분석 작업을 수행하는 데 사용됩니다.\n최근 경영, 마케팅, 판매, 고객서비스 등 다양한 분야에서 데이터 활용이 중요해 지고 있기 때문에 데이터 웨어하우스 도입 또한 빠르게 증가하고 있습니다.\n현재 시장에서 가장 인기 있는 데이터 웨어하우스 서비스는 클라우드 기반의 구글 빅쿼리(Google BigQuery), 아마존 레드시프트(Amazon Redshift), 스노우플레이크(Snowflake) 등 입니다.\n각 서비스의 장점과 단점이 명확하게 존재하기 때문에 어떤 데이터 웨어하우스를 도입하는 게 좋을까 고민이 될 수 있습니다. 데이터 웨어하우스는 그 특성상 한 번 도입하면 쉽게 변경하기가 어렵기 때문에 신중하게 선택해야 합니다.\n이 글에서는 빅쿼리, 스노우 플레이크, 레드 시프트의 장단점을 비교하고 어떤 데이터 웨어하우스를 선택해야 하는지에 대해 알아보겠습니다."
  },
  {
    "objectID": "posts/which-data-warehouse-to-choose/index.html#빅쿼리-vs-스노우-플레이크-vs-레드-시프트-비교",
    "href": "posts/which-data-warehouse-to-choose/index.html#빅쿼리-vs-스노우-플레이크-vs-레드-시프트-비교",
    "title": "클라우드 데이터 웨어하우스 어떤 기준으로 고를까?",
    "section": "2. 빅쿼리 vs 스노우 플레이크 vs 레드 시프트 비교",
    "text": "2. 빅쿼리 vs 스노우 플레이크 vs 레드 시프트 비교\n\n(1) 공통점\n\n클라우드 기반: 물리적 서버가 없는 클라우드 기반 서비스입니다.\nSQL 쿼리: SQL 쿼리를 사용하여 데이터를 처리합니다.\n데이터 분석: 데이터 분석, BI, 머신러닝 등 다양한 분석 작업을 수행할 수 있습니다.\n\n기능적으로는 3개 서비스가 큰 차이는 없습니다. 하지만 다음 차이점을 고려할 수 있습니다.\n\n\n(2) 차이점\n\n\n\n\n\n\n\n\n\n구분\n구글 빅쿼리\n스노우 플레이크\n아마존 레드 시프트\n\n\n\n\n비용\n최초 1TB/월 저장 비용 무료로 데이터 용량이 크지 않다면 가장 저렴\n데이터 저장 고정비 $23-$50/월 + 분석-계산 비용 별도 청구\n저장과 분석 비용이 가장 비쌈\n\n\n데이터 형식\nJSON, XML 기반 반정형 데이터 및 SQL 정형 데이터 지원\nJSON, XML, Avro, Parquet등 가장 다양한 형식 지원\nPostgreSQL 기반의 관계성 데이터를 JSON으로 지원\n\n\n아키텍처\n데이터 저장과 계산을 분리하여 빠른 속도 제공\n데이터 저장과 계산이 분리되고, 병렬 계산이 가능해서 속도가 빠름\n데이터 양이 많은 경우 처리 속ㄷ도가 느려질 수 있음\n\n\n확장성\n사용하는 만큼 자동으로 용량 조절하여 편리함\n\n데이터가 매우 많을 때는 가장 적합하다는 평\n\n\n사용 환경\n구글 클라우드 내에서만 사용 가능\n다양한 환경에서 사용 가능\n아마존 웹서비스 내에서만 사용 가능\n\n\n\n\n\n(1) 빅쿼리\n빅쿼리는 구글이 개발한 클라우드 기반 데이터 웨어하우스 서비스로, 서버리스 아키텍처를 사용하여 데이터를 저장하고 처리합니다. 빅쿼리는 SQL 쿼리를 사용하여 데이터를 처리하며, 데이터 분석, BI, 머신러닝 등 다양한 분석 작업을 수행할 수 있습니다.\n빅쿼리의 장점은 다음과 같습니다.\n\n빠른 속도: 빅쿼리는 대용량 데이터를 빠르게 처리할 수 있습니다.\n서버리스 아키텍처: 서버 관리가 필요 없어서 운영이 간편합니다.\n저렴한 비용: 사용한 만큼만 비용을 지불하면 되기 때문에 비용 효율적입니다.\n\n빅쿼리의 단점은 다음과 같습니다.\n\n지역 변경 불가: 지역으로 구분된 데이터 저장소를 변경할 수 없습니다. 변경하려면 새로운 프로젝트를 생성해서 복사하거나 이전할 수 있지만, 별도 비용이 발생합니다.\n지역 간 통합 분석 불가: 2개 이상 지역에 저장된 데이터셋을 통합하여 분석할 수 없습니다. 1개 지역으로 데이터롤 모아서 분석을 해야 합니다.\n\n\n\n(2) 스노우 플레이크\n스노우 플레이크는 클라우드 기반 데이터 웨어하우스 서비스로, 가상 데이터 웨어하우스를 사용하여 데이터를 저장하고 처리합니다. 스노우 플레이크는 SQL 쿼리를 사용하여 데이터를 처리하며, 데이터 분석, BI, 머신러닝 등 다양한 분석 작업을 수행할 수 있습니다.\n스노우 플레이크의 장점은 다음과 같습니다.\n\n빠른 속도: 스노우 플레이크는 대용량 데이터를 빠르게 처리할 수 있습니다.\n유연한 아키텍처: 가상 데이터 웨어하우스를 사용하여 데이터를 저장하고 처리하기 때문에 유연하게 확장할 수 있습니다.\n데이터 보안: 데이터 보안에 대한 우려가 적습니다.\n\n스노우 플레이크의 단점은 다음과 같습니다.\n\n비용: 빅쿼리에 비해 비용이 높을 수 있습니다.\n복잡한 쿼리: 복잡한 쿼리를 작성하기 어려울 수 있습니다.\n데이터 이관: 데이터를 스노우 플레이크로 이관하는 과정이 복잡할 수 있습니다.\n(3) 레드 시프트\n\n레드 시프트는 아마존이 개발한 클라우드 기반 데이터 웨어하우스 서비스로, 분산 데이터베이스를 사용하여 데이터를 저장하고 처리합니다. 레드 시프트는 SQL 쿼리를 사용하여 데이터를 처리하며, 데이터 분석, BI, 머신러닝 등 다양한 분석 작업을 수행할 수 있습니다.\n레드 시프트의 장점은 다음과 같습니다.\n\n확장성: 대용량 데이터를 가장 효율적으로 다룰 수 있습니다.\n\n레드 시프트의 단점은 다음과 같습니다.\n\n비용: 세 시스템 중 가장 비쌉니다.\n복잡한 쿼리: 복잡한 쿼리를 작성하기 어려울 수 있습니다.\n지원 형태 부족: JSON 형태만 지원해서 다양한 데이터베이스 연동이 어려울 수 있습니다."
  },
  {
    "objectID": "posts/which-data-warehouse-to-choose/index.html#고려할-사항은",
    "href": "posts/which-data-warehouse-to-choose/index.html#고려할-사항은",
    "title": "클라우드 데이터 웨어하우스 어떤 기준으로 고를까?",
    "section": "3. 고려할 사항은?",
    "text": "3. 고려할 사항은?\n데이터웨어하우스 클라우드 시스템을 선택하는 기업/기관의 상황과 여건이 다르기 때문에 어떤 시스템 하나가 유일한 정답이 될 수는 없습니다. 그럼에도 불구하고 데이터웨어하우스를 새로 구축하거나 이전하려고 한다면 다음 사항을 고려하면 좋겠습니다.\n\n어떤 종류의 데이터를 저장할 것인가?\n기존 데이터 시스템과 어떻게 결합/병합 할까?\n얼마나 유동적으로 데이터 사이즈가 변화할까?\n누가 관리할 것인가?\n얼마나 빠른 속도 데이터 처리가 필요할까?\n비용이 얼마나 들까?"
  },
  {
    "objectID": "posts/which-data-warehouse-to-choose/index.html#결론",
    "href": "posts/which-data-warehouse-to-choose/index.html#결론",
    "title": "클라우드 데이터 웨어하우스 어떤 기준으로 고를까?",
    "section": "4. 결론",
    "text": "4. 결론\n최근 가장 가파르게 확장되고 있는 서비스는 스노우플레이크 입니다. 다른 클라우드 서버와 연결이 가능하고, 다양한 분석 툴과 연계도 쉬운 편입니다. 또 구글, 아마존 생태계 내에 갇혀 있지 않아도 되는 것도 장점 입니다.\n반대로 만약 회사에서 주로 쓰는 서비스가 구글 애널리틱스 (GA4)라면, 굳이 다른 서비스를 연결하기 보다는 빅쿼리를 쓰는 게 쉽고 빠릅니다. 그래서 데이터 웨어하우스를 고를 때는 조직의 데이터 활용 기능과 시스템, 확장 가능성 등을 고려하여 신중히 결정하시기 바랍니다."
  },
  {
    "objectID": "posts/how-to-use-cafe24-api/index.html#데이터-분석가가-왜-api까지-쓰게-되었나",
    "href": "posts/how-to-use-cafe24-api/index.html#데이터-분석가가-왜-api까지-쓰게-되었나",
    "title": "비개발자도 쉽게 카페24 API 인증 토큰 발급 받는 방법",
    "section": "0. 데이터 분석가가 왜 API까지 쓰게 되었나",
    "text": "0. 데이터 분석가가 왜 API까지 쓰게 되었나\n저는 카페24를 활용하는 이커머스 데이터 분석을 종종 접하고 있는 데이터 분석가 입니다. 대부분 이커머스 사실 고객사 대표님들이 가장 궁금해 하시는 건 다음 2가지는\n\n“우리 회사 마케팅 활동이 매출에 잘 반영되고 있는지?”에 대한 설명\n“그래서 다음에 어떤 전략으로 매출을 늘릴 수 있는지?”에 대한 인사이트\n\n위 분석을 위해서는 정확한 매출 정보가 필요한데, 안타깝게도 GA4로는 정확한 매출 집계가 되기 어렵습니다. 특히 네이버페이 등 간편 결제로 발생하는 매출을 GA4에서 제공하는 태그 수집기로는 정확하게 잡아낼 수 없는 것이 가장 큰 이유 중 하나 입니다. 결국 이커머스 매출 성장을 위한 깊이 있는 데이터 기반 인사이트를 도출 하려면 카페24에서 제공하는 매출 정보를 GA4에서 수집한 웹행동 데이터와 결합하여야 합니다.\n이를 위해서는 다음과 같이 3단계 데이터 수집 과정이 필요합니다.\n\n\n\n\n\n\nNote\n\n\n\n\n매출 데이터: 카페24가 제공하는 관리자 페이지에서 엑셀로 추출 또는 카페24 API를 활용하여 수집\nGA4 웹 행동 데이터: 구글 애널리틱스에서 수집\n데이터 연동: 빅쿼리를 활용하여 데이터 연동 및 분석\n\n\n\n오늘은 이 중 첫번째 과정인 카페24 API를 활용한 매출 데이터 수집에 대해 설명 드리겠습니다."
  },
  {
    "objectID": "posts/how-to-use-cafe24-api/index.html#카페24-api-왜-다들-쓰지-않는가",
    "href": "posts/how-to-use-cafe24-api/index.html#카페24-api-왜-다들-쓰지-않는가",
    "title": "비개발자도 쉽게 카페24 API 인증 토큰 발급 받는 방법",
    "section": "1. 카페24 API, 왜 다들 쓰지 않는가?",
    "text": "1. 카페24 API, 왜 다들 쓰지 않는가?\n카페24 API는 카페24 플랫폼에 구축된 쇼핑몰의 데이터를 외부에서 읽거나 쓸 수 있도록 하는 인터페이스입니다. 카페24 API를 사용하면 쇼핑몰의 주문, 상품, 고객 정보 등을 외부 시스템과 연동하여 활용할 수 있습니다.\n대부분의 API 문서들은 백앤드 개발자를 대상으로 작성되어 있어서, 단계별 필요한 과정이 일부 생략되는 경우가 많습니다. 비개발자가 API 문서를 이해하고 활용하기 무척 어렵다고 느끼고 포기하는 원인 중 하나로 꼽을 수 있어요.\n특히 카페24 API는 1분간 유효한 인증 토큰을 발급 받은 후 접속용 토큰을 발급받아 계속 갱신해야 하는 체계로 운영되고 있습니다. 이 과정이 쉽지 않아서 비개발자들이 카페24 API를 활용하는 경우는 매우 드문 것 같습니다.\n하지만, 이번 포스팅을 통해 비개발자도 카페24 API를 활용할 수 있도록 첫번째 허들인 인증 토큰 발급 과정을 차근차근 설명해 드리겠습니다.\n\n주의사항: 이 포스팅은 제3자가 아닌 자사몰 데이터를 수집하고 활용하는 목적으로 작성 되었습니다. 카페24 API를 활용하여 타 쇼핑몰의 데이터를 수집하거나 활용하는 경우, 해당 쇼핑몰의 동의를 받아야 합니다. 또한, 카페24 API를 활용하여 수집한 데이터는 개인정보 보호법에 따라 안전하게 관리되어야 합니다."
  },
  {
    "objectID": "posts/how-to-use-cafe24-api/index.html#카페24-api-개발자사로-등록하기",
    "href": "posts/how-to-use-cafe24-api/index.html#카페24-api-개발자사로-등록하기",
    "title": "비개발자도 쉽게 카페24 API 인증 토큰 발급 받는 방법",
    "section": "2. 카페24 API 개발자(사)로 등록하기",
    "text": "2. 카페24 API 개발자(사)로 등록하기\n\n(1) 준비물\n\n카페24 쇼핑몰 관리자 계정: 구글 로그인 아닌 카페24 자체 계정을 만들어서 사용하세요.\n카페24 API 인증 토큰을 발급 받을 쇼핑몰 도메인 주소: https://관리자아이디.cafe24.com 을 씁니다.\n파이썬 코드를 작성할 수 있는 에디터: 주피터 노트북, VSCode, PyCharm 등을 사용하세요.\n\n\n\n(2) 카페24 개발자 센터 접속\n카페24 개발자 센터에 접속하여 관리자 계정으로 로그인 합니다. 카페24 개발자 센터\n처음 개발자 센터에 로그인하면 다음 절차가 필요합니다.\n- 이용약관 동의\n- 파트너 정보 입력\n카페24 개발자 센터는 쇼핑몰 운영을 위해 필요한 부가 서비스 개발하는 제3자(기업)를 위한 API 개발을 전제로 운영되고 있습니다. 이 제3자를 파트너라고 칭하고 있는데요, 개발자 센터 로그인할 때 어떤 파트너사 인지 정보를 입력하라고 하는 것입니다. 우리는 자체적으로 운영하는 쇼핑몰에서 API를 사용할 것이기 때문에 쇼핑몰을 운영하는 개인 또는 사업자 정보를 입력하고, 전문 분야는 “쇼핑몰 운영”으로 선택하면 됩니다.\n\n\n(3) App 등록\nAPI를 활용하기 위해서는 App을 등록해야 합니다. App은 API를 활용할 수 있는 권한을 부여받은 프로젝트라고 생각하시면 됩니다. 실제로 쇼핑몰 외에 별도 앱 서비스가 생성되지 않아도 API를 활용할 수 있습니다. 초보들이 보기에는 뭔가 거창한 앱을 개발해야 하는 것 처럼 느낄 수 있지만, 사실은 그냥 API를 활용할 수 있는 권한을 부여받기 위한 절차 입니다.\n\n카페24 API 등록을 위한 토큰 발급 전용 메뉴가 별도로 있다면 좋겠습니다.\n\n접속할 메뉴는 Apps &gt; App 관리 입니다. “ADD PRODUCT” 버튼을 클릭하여 새로운 App 등록을 시작합니다.\n버튼 클릭 시 다음과 같은 팝업이 뜨는데, 우리는 API 토큰만 발급받을 것이기 때문에 Web을 선택하고, 관리 상품명에는 쇼핑몰이름을 입력 합니다. 관리자아이디로 이미 샘플 쇼핑몰이 생성되기 때문에, 카페24 쇼핑몰 이름은 쇼핑몰 관리자아이디와 동일하게 입력하면 관리가 편할 것 입니다.\n\n\n\n카페24 API App 등록 화면 예시"
  },
  {
    "objectID": "posts/how-to-use-cafe24-api/index.html#카페24-api-개발-정보-등록",
    "href": "posts/how-to-use-cafe24-api/index.html#카페24-api-개발-정보-등록",
    "title": "비개발자도 쉽게 카페24 API 인증 토큰 발급 받는 방법",
    "section": "3. 카페24 API 개발 정보 등록",
    "text": "3. 카페24 API 개발 정보 등록\n\n(1) 기본 정보 입력하기\n우리는 쇼핑몰 운영자로서 데이터를 추출하기 위한 API를 사용할 것이기 때문에, 다음과 같이 정보를 입력합니다.\n\nApp URL: https://관리자아이디.cafe24.com\nApp URL은 API 접근 권한을 허용할 쇼핑몰 입니다. 각자의 관리자 로그인 아이디를 넣어주세요.\nRedirect URI: https://관리자아이디.cafe24.com/order/basket.html Redirect URI는 접근 권한을 부여하기 위해 1분간 유효한 인증코드를 받을 수 있는 홈페이지 주소 입니다. 해당 쇼핑몰 장바구니 페이지로 설정 했습니다.\n\n\n\n\n카페24 API 발급용 기본정보 입력 예시\n\n\n\n\n(2) API 정보 설정하기\n여기서는 API를 활용하여 추출할 데이터 범위를 설정합니다. 가능한 꼭 필요한 정보만 한정하여 설정하고 추후 필요한 경우 해당 권한을 추가할 수 있습니다. 매출 데이터 분석을 위해서는 주문과 상품, 회원 정보 “읽기”를 필수로 설정합니다.\n나머지 부분은 별도로 설정하지 않습니다.\n\n\n\n카페24 API 정보 입력 예시\n\n\n\n\n(3) API 인증 정보 메모하기\n위 설정을 마치고 인증 정보에서 Client ID와 Client Secret을 복사하여 따로 메모해 둡니다. 이 정보는 곧 발급 받을 인증 코드를 받을 때 사용합니다.\n\n\n\n카페24 API 인증정보 저장하기\n\n\n이 때 메모장에 복사해 두어도 되지만, 4번을 참고하여 파이썬 코드 에디터를 열고 다음과 같이 변수를 지정하는 것을 추천합니다.\nclient_id = \"발급받은 Client ID\"\nclient_secret = \"발급받은 Client Secret\"\n\n\n(4) 입력한 정보 저장하기\nWebHook 설정은 필수가 아니기 때문에 별도로 설정하지 않습니다.\n페이지 하단 또는 상단의 파란색 “저장” 버튼을 클릭하여 설정한 정보를 저장합니다."
  },
  {
    "objectID": "posts/how-to-use-cafe24-api/index.html#인증코드-받기",
    "href": "posts/how-to-use-cafe24-api/index.html#인증코드-받기",
    "title": "비개발자도 쉽게 카페24 API 인증 토큰 발급 받는 방법",
    "section": "4. 인증코드 받기",
    "text": "4. 인증코드 받기\n\n(1) 준비물\n\n파이썬 코드 에디터: 주피터 노트북, VSCode, PyCharm 등 (이 블로그에서는 VSCode를 사용합니다.)\n카페24 API 인증 정보: Client ID, Client Secret\nRedirect URI: https://관리자아이디.cafe24.com/order/list.html\n웹브라우저: 크롬, 사파리, 엣지 등\n\n\n\n(2) 파이썬 코드로 인증받을 URL 생성하기\n카페24 API 인증 코드를 받기 위해서는 다음과 같은 코드로 각자 쇼핑몰 인증코드를 받을 URL을 생성해야 합니다.\n\n가. 기존에 설정한 정보들: 각자 쇼핑몰 환경에 따라 설정 하세요.\n\nmall_id = “관리자 또는 쇼핑몰 아이디”\nclient_id = “발급받은 Client ID”\nclient_secret = “발급받은 Client Secret”\nredirect_uri = f”https://{mall_id}.cafe24.com/order/list.html”\n\n\n\n나. 추가로 지정할 정보들: 그대로 복사하여 사용\n{state}는 app_install로 지정하여 인증 코드 받을 때 확인하는 용도 입니다. 다른 문자열을 넣어도 관계는 없습니다.\n\nstate = “app_install”\n\n{scope}는 각자 API 활용 범위에 따라 달라지는데, 여기서는 3번에서 매출 데이터를 수집하기 위해 필요한 주문, 상품, 회원 정보를 읽는 것으로 지정 합니다. 개별적으로 변경을 원하는 경우, 카페24 API Scope별 사용 동의 문서를 참고하세요.\n아래 예시는 앱 설치 활용 권한, 주문 데이터 읽기, 상품 데이터 읽기, 고객 데이터 읽기 권한으로 정의 되어 있습니다. 쇼핑몰 고객 매출 정보 분석에는 이 정도 권한이면 충분 합니다.\n\nscope = “mall.read_application,mall.write_application,mall.read_product,mall.read_order,mall.read_customer”\n\n# (1) 필요한 변수 지정: 각자 작성 \nmall_id = \"관리자 또는 쇼핑몰 아이디\"\nclient_id = \"발급받은 Client ID\"\nclient_secret = \"발급받은 Client Secret\"\nredirect_uri = f\"https://{mall_id}.cafe24.com/order/basket.html\"\nstate = \"app_install\"\nscope = \"mall.read_application,mall.write_application,mall.read_product,mall.read_order,mall.read_customer\"\n\n# (2) 인증 코드를 받기 위한 URL 생성: 그대로 복사 \nurl = f\"\"\"https://{mall_id}.cafe24api.com/api/v2/oauth/authorize?response_type=code\n&client_id={client_id}&state={state}&redirect_uri={redirect_uri}&scope={scope}\"\"\"\nprint(url)\n코드를 실행하면 각자의 쇼핑몰 정보로 완성된 URL이 터미널에 출력됩니다. 웹주소 전체를 복사하여 웹브라우저에 붙여넣기 한 후 접속합니다.\n\n\n\n파이썬으로 생성한 접속코드 발급용 URL 예시\n\n\n최초 접속 시 API 접속 권한을 승인하기 위해 관리자 로그인 화면이 뜹니다. 자세한 단계별 방법은 아래 동영상으로 확인 하세요.\n\n인증 코드는 1분간 유효 하기 때문에코드 발급 후 재빠르게 다음 단계를 실행해서 재활용 가능한 토큰으로 교환해야 합니다. 토큰 교환 방법은 다음 글에서 자세하게 소개해 들겠습니다."
  }
]